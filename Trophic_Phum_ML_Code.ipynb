{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Chl-a & NDCL"
      ],
      "metadata": {
        "id": "nI2SptkSZIH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NDCI -> Chlorophyll-a (µg/L) + NDCI mapping script (single-season, Sentinel-2)\n",
        "# Requirements: rasterio, numpy, matplotlib, pyproj, scikit-image\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.transform import array_bounds\n",
        "from rasterio.warp import reproject, Resampling\n",
        "from pyproj import CRS, Transformer\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import morphology\n",
        "import matplotlib.image as mpimg\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ------------------ USER SETTINGS ------------------\n",
        "B4_PATH = \"/content/drive/MyDrive/Pandas.Monsoon/Band_4.tif\"\n",
        "B5_PATH = \"/content/drive/MyDrive/Pandas/Chl-a/Ysoon/Band_5.tif\"\n",
        "B3_PATH = \"/content/drive/MyDrive/Pan/3.Monsoon/Band_3.tif\"\n",
        "B8_PATH = \"/content/drive/MyDrive/Pta/2022/3.Monsoon/Band_8.tif\"\n",
        "\n",
        "OUT_DIR = \"/content/drive/MyDrive/Pandast_Monsoon\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# NDCI -> Chl conversion\n",
        "CONVERT_METHOD = 'piecewise'  # 'piecewise' or 'regression'\n",
        "reg_a = None                  # used only if method='regression'\n",
        "reg_b = None\n",
        "\n",
        "# Masks\n",
        "NDWI_THRESHOLD = 0.05\n",
        "VEG_THRESHOLD = 0.18\n",
        "MIN_PHUMDIS_PIXELS = 30\n",
        "\n",
        "# ------------------ HELPER FUNCTIONS ------------------\n",
        "def read_band(path):\n",
        "    \"\"\"Read band, convert to float, scale 0–1 if needed, set nodata to NaN.\"\"\"\n",
        "    with rasterio.open(path) as src:\n",
        "        arr = src.read(1).astype('float32')\n",
        "        prof = src.profile.copy()\n",
        "        nod = src.nodata\n",
        "    if nod is not None:\n",
        "        arr[arr == nod] = np.nan\n",
        "    finite = np.isfinite(arr)\n",
        "    if finite.any() and float(np.nanmax(arr[finite])) > 1.5:\n",
        "        arr[finite] = arr[finite] / 10000.0  # scale reflectance\n",
        "    return np.clip(arr, 0.0, 1.5), prof\n",
        "\n",
        "def compute_ndci(b5, b4):\n",
        "    eps = 1e-9\n",
        "    return np.divide(\n",
        "        (b5 - b4), (b5 + b4 + eps),\n",
        "        out=np.full_like(b5, np.nan),\n",
        "        where=np.isfinite(b5) & np.isfinite(b4)\n",
        "    )\n",
        "\n",
        "def compute_water_mask(b3, b8, ndwi_threshold=NDWI_THRESHOLD):\n",
        "    eps = 1e-9\n",
        "    ndwi = np.divide(\n",
        "        (b3 - b8), (b3 + b8 + eps),\n",
        "        out=np.full_like(b3, np.nan),\n",
        "        where=np.isfinite(b3) & np.isfinite(b8)\n",
        "    )\n",
        "    water = (ndwi > ndwi_threshold) & np.isfinite(ndwi)\n",
        "    return water, ndwi\n",
        "\n",
        "def compute_phumdis_mask(b8, b4=None, b3=None,\n",
        "                         veg_threshold=VEG_THRESHOLD,\n",
        "                         water_mask=None,\n",
        "                         min_size=MIN_PHUMDIS_PIXELS):\n",
        "    \"\"\"Simple vegetation/‘phumdis’ mask using NIR–Red or NIR–Green index.\"\"\"\n",
        "    eps = 1e-9\n",
        "    if b4 is not None:\n",
        "        num = b8 - b4\n",
        "        den = b8 + b4 + eps\n",
        "    else:\n",
        "        num = b8 - b3\n",
        "        den = b8 + b3 + eps\n",
        "\n",
        "    vi = np.divide(\n",
        "        num, den,\n",
        "        out=np.full_like(num, np.nan),\n",
        "        where=np.isfinite(num) & np.isfinite(den)\n",
        "    )\n",
        "\n",
        "    raw = (vi >= veg_threshold) & np.isfinite(vi)\n",
        "    if water_mask is not None:\n",
        "        raw &= water_mask\n",
        "\n",
        "    cleaned = morphology.remove_small_objects(raw.astype(bool), min_size=min_size)\n",
        "    cleaned = morphology.remove_small_holes(cleaned, area_threshold=int(min_size/2))\n",
        "    return cleaned.astype('uint8'), vi\n",
        "\n",
        "def convert_ndci_to_chl(ndci_arr, method='piecewise', a=None, b=None):\n",
        "    \"\"\"Convert NDCI to approximate Chl-a (µg/L).\"\"\"\n",
        "    if method == 'regression':\n",
        "        chl = a * ndci_arr + b\n",
        "        chl[~np.isfinite(chl)] = np.nan\n",
        "        return chl.astype('float32')\n",
        "\n",
        "    # --- Piecewise (class-based) relationship ---\n",
        "    chl = np.full_like(ndci_arr, np.nan, dtype='float32')\n",
        "\n",
        "    # Very low NDCI -> low Chl\n",
        "    chl[np.isfinite(ndci_arr) & (ndci_arr <= -0.1)] = 3.5\n",
        "\n",
        "    # -0.1 to 0.1 -> 7.5–25\n",
        "    mask = np.isfinite(ndci_arr) & (ndci_arr > -0.1) & (ndci_arr <= 0.1)\n",
        "    if np.any(mask):\n",
        "        x = ndci_arr[mask]\n",
        "        chl[mask] = 7.5 + (x + 0.1)/0.2 * (25 - 7.5)\n",
        "\n",
        "    # 0.1 to 0.2 -> 25–33\n",
        "    mask = np.isfinite(ndci_arr) & (ndci_arr > 0.1) & (ndci_arr <= 0.2)\n",
        "    if np.any(mask):\n",
        "        x = ndci_arr[mask]\n",
        "        chl[mask] = 25 + (x - 0.1)/0.1 * (33 - 25)\n",
        "\n",
        "    # 0.2 to 0.5 -> 33–50\n",
        "    mask = np.isfinite(ndci_arr) & (ndci_arr > 0.2) & (ndci_arr <= 0.5)\n",
        "    if np.any(mask):\n",
        "        x = ndci_arr[mask]\n",
        "        chl[mask] = 33 + (x - 0.2)/0.3 * (50 - 33)\n",
        "\n",
        "    # Very high NDCI\n",
        "    chl[np.isfinite(ndci_arr) & (ndci_arr > 0.5)] = 60\n",
        "\n",
        "    return chl\n",
        "\n",
        "def add_scalebar(ax, extent, length_km=2, linewidth=3, fontsize=12):\n",
        "    \"\"\"\n",
        "    Add a simple scale bar in km in the lower-left corner of a lon/lat map.\n",
        "    extent = (lon_min, lon_max, lat_min, lat_max)\n",
        "    \"\"\"\n",
        "    lon_min, lon_max, lat_min, lat_max = extent\n",
        "    dx = lon_max - lon_min\n",
        "    dy = lat_max - lat_min\n",
        "    lat_center = (lat_min + lat_max) / 2.0\n",
        "\n",
        "    # approximate meters per degree longitude at this latitude\n",
        "    m_per_deg_lon = 111320 * np.cos(np.deg2rad(lat_center))\n",
        "    length_deg = (length_km * 1000.0) / m_per_deg_lon\n",
        "\n",
        "    # start and end of bar\n",
        "    x_start = lon_min + 0.05 * dx\n",
        "    x_end = x_start + length_deg\n",
        "    y = lat_min + 0.05 * dy\n",
        "\n",
        "    ax.plot([x_start, x_end], [y, y], color='k', linewidth=linewidth)\n",
        "    ax.text((x_start + x_end)/2.0,\n",
        "            y + 0.01 * dy,\n",
        "            f\"{length_km} km\",\n",
        "            ha='center', va='bottom',\n",
        "            fontsize=fontsize,\n",
        "            fontweight='bold')\n",
        "\n",
        "# ------------------ MAIN WORKFLOW ------------------\n",
        "\n",
        "# --- Read B4 and use it as reference grid ---\n",
        "B4, prof_b4 = read_band(B4_PATH)\n",
        "ref_shape = B4.shape\n",
        "ref_transform = prof_b4['transform']\n",
        "ref_crs = prof_b4['crs']\n",
        "\n",
        "# --- Read and align B5 ---\n",
        "B5, prof_b5 = read_band(B5_PATH)\n",
        "if B5.shape != ref_shape:\n",
        "    print(f\"Warning: B5 shape {B5.shape} != B4 shape {ref_shape}. Reprojecting B5.\")\n",
        "    B5_reprojected = np.empty(ref_shape, dtype=B5.dtype)\n",
        "    reproject(\n",
        "        source=B5,\n",
        "        destination=B5_reprojected,\n",
        "        src_transform=prof_b5['transform'],\n",
        "        src_crs=prof_b5['crs'],\n",
        "        dst_transform=ref_transform,\n",
        "        dst_crs=ref_crs,\n",
        "        resampling=Resampling.bilinear\n",
        "    )\n",
        "    B5 = B5_reprojected\n",
        "\n",
        "# --- Read and align B3 ---\n",
        "B3, prof_b3 = read_band(B3_PATH)\n",
        "if B3.shape != ref_shape:\n",
        "    print(f\"Warning: B3 shape {B3.shape} != B4 shape {ref_shape}. Reprojecting B3.\")\n",
        "    B3_reprojected = np.empty(ref_shape, dtype=B3.dtype)\n",
        "    reproject(\n",
        "        source=B3,\n",
        "        destination=B3_reprojected,\n",
        "        src_transform=prof_b3['transform'],\n",
        "        src_crs=prof_b3['crs'],\n",
        "        dst_transform=ref_transform,\n",
        "        dst_crs=ref_crs,\n",
        "        resampling=Resampling.bilinear\n",
        "    )\n",
        "    B3 = B3_reprojected\n",
        "\n",
        "# --- Read and align B8 ---\n",
        "B8, prof_b8 = read_band(B8_PATH)\n",
        "if B8.shape != ref_shape:\n",
        "    print(f\"Warning: B8 shape {B8.shape} != B4 shape {ref_shape}. Reprojecting B8.\")\n",
        "    B8_reprojected = np.empty(ref_shape, dtype=B8.dtype)\n",
        "    reproject(\n",
        "        source=B8,\n",
        "        destination=B8_reprojected,\n",
        "        src_transform=prof_b8['transform'],\n",
        "        src_crs=prof_b8['crs'],\n",
        "        dst_transform=ref_transform,\n",
        "        dst_crs=ref_crs,\n",
        "        resampling=Resampling.bilinear\n",
        "    )\n",
        "    B8 = B8_reprojected\n",
        "\n",
        "# Use B4 profile for everything\n",
        "prof = prof_b4\n",
        "\n",
        "# --- Indices & masks ---\n",
        "ndci = compute_ndci(B5, B4)\n",
        "water_mask, ndwi = compute_water_mask(B3, B8)\n",
        "phumdis_mask, veg_index = compute_phumdis_mask(\n",
        "    B8, b4=B4, b3=B3, water_mask=water_mask\n",
        ")\n",
        "\n",
        "# Mask phumdis out of NDCI\n",
        "ndci_masked = ndci.copy()\n",
        "ndci_masked[phumdis_mask == 1] = np.nan\n",
        "\n",
        "# Approximate Chl-a\n",
        "chl = convert_ndci_to_chl(ndci_masked,\n",
        "                          method=CONVERT_METHOD,\n",
        "                          a=reg_a,\n",
        "                          b=reg_b)\n",
        "\n",
        "# ------------------ PLOTTING SETTINGS ------------------\n",
        "NORTH_ARROW_PATH = \"/content/drive/MyDrive/Pandas/Chl-a/Yearly Cliped_Data/Compass.jpg\"\n",
        "NORTH_X = 0.13\n",
        "NORTH_Y = 0.80\n",
        "NORTH_SIZE = 0.13\n",
        "\n",
        "FONT_TICK = 14\n",
        "FONT_CBAR = 14\n",
        "FONT_CBAR_LABEL = 16\n",
        "\n",
        "# ---- Compute extent in lon/lat ----\n",
        "height, width = chl.shape\n",
        "left, bottom, right, top = array_bounds(height, width, prof['transform'])\n",
        "src_crs = CRS.from_user_input(prof['crs'])\n",
        "\n",
        "if src_crs.is_geographic:\n",
        "    extent = (left, right, bottom, top)\n",
        "else:\n",
        "    transformer = Transformer.from_crs(src_crs, \"EPSG:4326\", always_xy=True)\n",
        "    lon_left, lat_bottom = transformer.transform(left, bottom)\n",
        "    lon_right, lat_top = transformer.transform(right, top)\n",
        "    extent = (lon_left, lon_right, lat_bottom, lat_top)\n",
        "\n",
        "# Shared tick locations\n",
        "xticks = np.linspace(extent[0], extent[1], 5)\n",
        "yticks = np.linspace(extent[2], extent[3], 5)\n",
        "\n",
        "# ====================================================\n",
        "# 1) CHLOROPHYLL-a MAP\n",
        "# ====================================================\n",
        "finite_chl = chl[np.isfinite(chl)]\n",
        "vmin_chl = np.nanpercentile(finite_chl, 2)\n",
        "vmax_chl = np.nanpercentile(finite_chl, 98)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10), dpi=600)\n",
        "\n",
        "im = ax.imshow(chl, cmap='viridis', origin='upper',\n",
        "               vmin=vmin_chl, vmax=vmax_chl, extent=extent)\n",
        "\n",
        "ax.set_xticks(xticks)\n",
        "ax.set_yticks(yticks)\n",
        "\n",
        "ax.set_xticklabels(\n",
        "    [f\"{x:.4f}°E\" for x in xticks],\n",
        "    rotation=15,\n",
        "    fontsize=18,\n",
        "    fontweight='bold'\n",
        ")\n",
        "ax.set_yticklabels(\n",
        "    [f\"{y:.4f}°N\" for y in yticks],\n",
        "    fontsize=18,\n",
        "    fontweight='bold'\n",
        ")\n",
        "\n",
        "ax.set_xlabel(\"\")\n",
        "ax.set_ylabel(\"\")\n",
        "ax.tick_params(axis='both', width=1.5, length=6)\n",
        "\n",
        "# North arrow\n",
        "if os.path.exists(NORTH_ARROW_PATH):\n",
        "    north_img = mpimg.imread(NORTH_ARROW_PATH)\n",
        "    ax_n = fig.add_axes([NORTH_X, NORTH_Y, NORTH_SIZE, NORTH_SIZE])\n",
        "    ax_n.imshow(north_img)\n",
        "    ax_n.axis(\"off\")\n",
        "\n",
        "# Scale bar (e.g., 2 km)\n",
        "add_scalebar(ax, extent, length_km=2, linewidth=3, fontsize=14)\n",
        "\n",
        "# Colorbar\n",
        "cbar = fig.colorbar(im, ax=ax, fraction=0.04, pad=0.02)\n",
        "cbar.ax.tick_params(labelsize=FONT_CBAR, width=1.5)\n",
        "for label in cbar.ax.get_yticklabels():\n",
        "    label.set_fontweight('bold')\n",
        "cbar.outline.set_linewidth(1.5)\n",
        "cbar.set_label(\"Chlorophyll-a (µg L⁻¹)\",\n",
        "               fontsize=FONT_CBAR_LABEL,\n",
        "               fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR, \"Chl_NDCI_map.png\"),\n",
        "            dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# ====================================================\n",
        "# 2) NDCI MAP (same style)\n",
        "# ====================================================\n",
        "finite_ndci = ndci_masked[np.isfinite(ndci_masked)]\n",
        "vmin_ndci = np.nanpercentile(finite_ndci, 2)\n",
        "vmax_ndci = np.nanpercentile(finite_ndci, 98)\n",
        "\n",
        "fig2, ax2 = plt.subplots(figsize=(10, 10), dpi=600)\n",
        "\n",
        "im2 = ax2.imshow(ndci_masked, cmap='turbo', origin='upper',\n",
        "                 vmin=vmin_ndci, vmax=vmax_ndci, extent=extent)\n",
        "\n",
        "ax2.set_xticks(xticks)\n",
        "ax2.set_yticks(yticks)\n",
        "\n",
        "ax2.set_xticklabels(\n",
        "    [f\"{x:.4f}°E\" for x in xticks],\n",
        "    rotation=15,\n",
        "    fontsize=18,\n",
        "    fontweight='bold'\n",
        ")\n",
        "ax2.set_yticklabels(\n",
        "    [f\"{y:.4f}°N\" for y in yticks],\n",
        "    fontsize=18,\n",
        "    fontweight='bold'\n",
        ")\n",
        "\n",
        "ax2.set_xlabel(\"\")\n",
        "ax2.set_ylabel(\"\")\n",
        "ax2.tick_params(axis='both', width=1.5, length=6)\n",
        "\n",
        "# North arrow\n",
        "if os.path.exists(NORTH_ARROW_PATH):\n",
        "    north_img = mpimg.imread(NORTH_ARROW_PATH)\n",
        "    ax2_n = fig2.add_axes([NORTH_X, NORTH_Y, NORTH_SIZE, NORTH_SIZE])\n",
        "    ax2_n.imshow(north_img)\n",
        "    ax2_n.axis(\"off\")\n",
        "\n",
        "# Scale bar for NDCI map (same length)\n",
        "add_scalebar(ax2, extent, length_km=2, linewidth=3, fontsize=12)\n",
        "\n",
        "# Colorbar for NDCI\n",
        "cbar2 = fig2.colorbar(im2, ax=ax2, fraction=0.04, pad=0.02)\n",
        "cbar2.ax.tick_params(labelsize=FONT_CBAR, width=1.5)\n",
        "for label in cbar2.ax.get_yticklabels():\n",
        "    label.set_fontweight('bold')\n",
        "cbar2.outline.set_linewidth(1.5)\n",
        "cbar2.set_label(\"NDCI\",\n",
        "                fontsize=FONT_CBAR_LABEL,\n",
        "                fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR, \"NDCI_map.png\"),\n",
        "            dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-Ryvsv8XZKkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ML"
      ],
      "metadata": {
        "id": "Drai6AtFZMBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RF_Before Hypertuning"
      ],
      "metadata": {
        "id": "aG8reOWLZP81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# IMPORTS\n",
        "# =====================================================\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.features import geometry_mask\n",
        "import geopandas as gpd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "from skimage.morphology import dilation, disk   # for bloom expansion\n",
        "\n",
        "# =====================================================\n",
        "# CONFIG  (EDIT THESE PATHS)\n",
        "# =====================================================\n",
        "SCENES_DIR = \"/content/drive/MyDrive\"\n",
        "SHP_PATH   = \"/content/drive/MyDrive\"\n",
        "SAMPLES_PER_SCENE = 5000   # random samples per scene for ML\n",
        "\n",
        "# NDVI thresholds for phumdis\n",
        "VEG_SPARSE = 0.20\n",
        "VEG_DENSE  = 0.40\n",
        "\n",
        "# Clean-water threshold fixed, bloom threshold from data\n",
        "CHL_T1_FIXED      = 20.0     # clean vs nutrient-rich\n",
        "BLOOM_PERCENTILE  = 85       # bloom = top 15% of Chl inside lake  (Option 1)\n",
        "\n",
        "# Hybrid bloom rule thresholds (Option 2)\n",
        "NDCI_BLOOM_MIN = 0.15\n",
        "NDVI_BLOOM_MIN = 0.25\n",
        "\n",
        "# Morphological expansion radius in pixels (Option 3)\n",
        "BLOOM_DILATE_RADIUS = 2      # 2–3 is reasonable\n",
        "\n",
        "# =====================================================\n",
        "# HELPER: Read stacked Sentinel-2 TIFF (B2–B12)\n",
        "# =====================================================\n",
        "def read_stack_reflectance(path):\n",
        "    print(f\"Reading {path}...\")\n",
        "    with rasterio.open(path) as src:\n",
        "        stack = src.read().astype(\"float32\")\n",
        "        prof  = src.profile.copy()\n",
        "\n",
        "    finite = np.isfinite(stack)\n",
        "    if finite.any() and float(np.nanmax(stack[finite])) > 1.5:\n",
        "        stack = np.where(finite, stack / 10000.0, np.nan)\n",
        "\n",
        "    return np.clip(stack, 0.0, 1.5), prof\n",
        "\n",
        "# =====================================================\n",
        "# HELPER: Parse \"2021_Monsoon.tif\" → (year, season, base)\n",
        "# =====================================================\n",
        "def parse_scene_name(path):\n",
        "    base  = os.path.basename(path).replace(\".tif\", \"\")\n",
        "    parts = base.split(\"_\", 1)\n",
        "    if len(parts) == 2:\n",
        "        year, season = parts\n",
        "    else:\n",
        "        year, season = \"Unknown\", base\n",
        "    return year, season, base\n",
        "\n",
        "# =====================================================\n",
        "# LOAD LAKE SHAPEFILE\n",
        "# =====================================================\n",
        "print(\"Loading lake mask shapefile:\", SHP_PATH)\n",
        "gdf_lake = gpd.read_file(SHP_PATH)\n",
        "\n",
        "scene_files = sorted(glob.glob(os.path.join(SCENES_DIR, \"*.tif\")))\n",
        "print(\"Found scenes:\", len(scene_files))\n",
        "if not scene_files:\n",
        "    raise RuntimeError(\"No .tif files found in SCENES_DIR\")\n",
        "\n",
        "# =====================================================\n",
        "# PASS 1: COLLECT Chl VALUES TO SET BLOOM THRESHOLD\n",
        "# =====================================================\n",
        "all_chl_values = []\n",
        "\n",
        "for scene_path in scene_files:\n",
        "    _, _, base = parse_scene_name(scene_path)\n",
        "    print(f\"\\n[PASS 1] Collecting Chl from: {base}\")\n",
        "\n",
        "    stack, prof = read_stack_reflectance(scene_path)\n",
        "    _, H, W = stack.shape\n",
        "\n",
        "    gdf_proj = gdf_lake.to_crs(prof[\"crs\"])\n",
        "    lake_mask = geometry_mask(\n",
        "        gdf_proj.geometry,\n",
        "        transform=prof[\"transform\"],\n",
        "        invert=True,\n",
        "        out_shape=(H, W)\n",
        "    )\n",
        "\n",
        "    B4 = stack[2]   # Red\n",
        "    B5 = stack[3]   # RE1\n",
        "    eps = 1e-9\n",
        "\n",
        "    ndci = (B5 - B4) / (B5 + B4 + eps)\n",
        "    chl  = 14.039 + 86.115 * ndci + 194.325 * (ndci ** 2)\n",
        "\n",
        "    valid = lake_mask & np.isfinite(chl)\n",
        "    if np.any(valid):\n",
        "        all_chl_values.append(chl[valid])\n",
        "\n",
        "if not all_chl_values:\n",
        "    raise RuntimeError(\"No valid Chl values inside lake in any scene.\")\n",
        "\n",
        "all_chl_values = np.concatenate(all_chl_values)\n",
        "p50, p75, p85, p90, p95 = np.percentile(all_chl_values, [50, 75, 85, 90, 95])\n",
        "\n",
        "print(\"\\nChl-a percentiles inside lake (µg/L):\")\n",
        "print(f\"50%: {p50:.2f}, 75%: {p75:.2f}, 85%: {p85:.2f}, 90%: {p90:.2f}, 95%: {p95:.2f}\")\n",
        "\n",
        "CHL_T1 = CHL_T1_FIXED\n",
        "CHL_T2 = float(np.percentile(all_chl_values, BLOOM_PERCENTILE))  # Option 1\n",
        "\n",
        "print(f\"\\nUsing thresholds:\")\n",
        "print(f\"  CHL_T1 = {CHL_T1:.2f} µg/L (clean vs nutrient)\")\n",
        "print(f\"  CHL_T2 = {CHL_T2:.2f} µg/L (nutrient vs bloom; {BLOOM_PERCENTILE}th percentile)\")\n",
        "\n",
        "# =====================================================\n",
        "# HELPER: Build class map from stack (Options 1–3 inside)\n",
        "# =====================================================\n",
        "def build_classes_from_stack(stack, lake_mask):\n",
        "    \"\"\"\n",
        "    Creates 5 classes (0–4) using:\n",
        "      - CHL_T1 & CHL_T2 (Option 1)\n",
        "      - Hybrid bloom rule: high Chl OR (high NDCI & high NDVI) (Option 2)\n",
        "      - Morphological expansion of bloom (Option 3)\n",
        "    \"\"\"\n",
        "    B2 = stack[0]\n",
        "    B3 = stack[1]\n",
        "    B4 = stack[2]    # Red\n",
        "    B5 = stack[3]    # RE1\n",
        "    B8 = stack[6]    # NIR\n",
        "\n",
        "    eps = 1e-9\n",
        "\n",
        "    ndvi = (B8 - B4) / (B8 + B4 + eps)\n",
        "    ndci = (B5 - B4) / (B5 + B4 + eps)\n",
        "    chl  = 14.039 + 86.115 * ndci + 194.325 * (ndci ** 2)\n",
        "\n",
        "    class_map = np.full(B4.shape, np.nan, dtype=\"float32\")\n",
        "\n",
        "    # Phumdis first\n",
        "    dense  = (ndvi >= VEG_DENSE) & lake_mask\n",
        "    sparse = (ndvi >= VEG_SPARSE) & (ndvi < VEG_DENSE) & lake_mask\n",
        "    water  = (ndvi < VEG_SPARSE) & lake_mask\n",
        "\n",
        "    class_map[dense]  = 4   # Dense phumdis\n",
        "    class_map[sparse] = 3   # Sparse phumdis\n",
        "\n",
        "    # --- Bloom logic ---\n",
        "\n",
        "    # 1) Core bloom based on high Chl\n",
        "    bloom_core = (chl >= CHL_T2) & water\n",
        "\n",
        "    # 2) Spectral bloom: high NDCI & high NDVI\n",
        "    bloom_spectral = ((ndci > NDCI_BLOOM_MIN) & (ndvi > NDVI_BLOOM_MIN)) & water\n",
        "\n",
        "    # Combine\n",
        "    bloom = bloom_core | bloom_spectral\n",
        "\n",
        "    # 3) Morphological expansion (Option 3)\n",
        "    if BLOOM_DILATE_RADIUS > 0:\n",
        "        bloom = dilation(bloom, disk(BLOOM_DILATE_RADIUS)) & water\n",
        "\n",
        "    # Set bloom first\n",
        "    class_map[bloom] = 2\n",
        "\n",
        "    # Remaining water pixels (not bloom & not phumdis)\n",
        "    water_remain = water & (~bloom)\n",
        "\n",
        "    class_map[(chl < CHL_T1) & water_remain] = 0             # Clean\n",
        "    class_map[(chl >= CHL_T1) & water_remain] = 1            # Nutrient-rich\n",
        "\n",
        "    return class_map, chl, ndvi, ndci\n",
        "\n",
        "# =====================================================\n",
        "# PASS 2: BUILD ML DATASET X, y, years, seasons\n",
        "# =====================================================\n",
        "X_list, y_list = [], []\n",
        "year_list, season_list = [], []\n",
        "\n",
        "for scene_path in scene_files:\n",
        "    year, season, base = parse_scene_name(scene_path)\n",
        "    print(f\"\\n[PASS 2] Building dataset from: {base}\")\n",
        "\n",
        "    stack, prof = read_stack_reflectance(scene_path)\n",
        "    n_bands, H, W = stack.shape\n",
        "\n",
        "    gdf_proj = gdf_lake.to_crs(prof[\"crs\"])\n",
        "    lake_mask = geometry_mask(\n",
        "        gdf_proj.geometry,\n",
        "        transform=prof[\"transform\"],\n",
        "        invert=True,\n",
        "        out_shape=(H, W)\n",
        "    )\n",
        "\n",
        "    class_map, chl, ndvi, ndci = build_classes_from_stack(stack, lake_mask)\n",
        "\n",
        "    valid = np.isfinite(class_map)\n",
        "    if not np.any(valid):\n",
        "        print(\" -> No valid labeled pixels, skipping.\")\n",
        "        continue\n",
        "\n",
        "    flat_stack = stack.reshape(n_bands, -1).T\n",
        "    flat_ndvi  = ndvi.flatten()\n",
        "    flat_ndci  = ndci.flatten()\n",
        "    flat_chl   = chl.flatten()\n",
        "    flat_cls   = class_map.flatten()\n",
        "    flat_valid = valid.flatten()\n",
        "\n",
        "    idx = np.where(flat_valid)[0]\n",
        "\n",
        "    feat = np.column_stack([\n",
        "        flat_stack[idx],\n",
        "        flat_ndvi[idx],\n",
        "        flat_ndci[idx],\n",
        "        flat_chl[idx]\n",
        "    ])\n",
        "    labels = flat_cls[idx]\n",
        "\n",
        "    if len(labels) > SAMPLES_PER_SCENE:\n",
        "        sel = np.random.choice(len(labels), SAMPLES_PER_SCENE, replace=False)\n",
        "        feat   = feat[sel]\n",
        "        labels = labels[sel]\n",
        "\n",
        "    X_list.append(feat)\n",
        "    y_list.append(labels)\n",
        "    year_list.extend([year] * len(labels))\n",
        "    season_list.extend([season] * len(labels))\n",
        "\n",
        "# Concatenate all scenes\n",
        "X = np.concatenate(X_list, axis=0)\n",
        "y = np.concatenate(y_list, axis=0)\n",
        "years   = np.array(year_list)\n",
        "seasons = np.array(season_list)\n",
        "\n",
        "print(\"\\nFINAL DATASET SHAPES\")\n",
        "print(\"X:\", X.shape)\n",
        "print(\"y:\", y.shape)\n",
        "\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "print(\"\\nClass counts:\")\n",
        "for cls, c in zip(unique, counts):\n",
        "    print(f\"  Class {int(cls)} = {c} samples\")\n",
        "print(\"Seasons:\", np.unique(seasons))\n",
        "print(\"Years:\",   np.unique(years))\n",
        "\n",
        "# =====================================================\n",
        "# TRAIN RF + CONFUSION MATRICES\n",
        "# =====================================================\n",
        "X_train, X_test, y_train, y_test, seasons_train, seasons_test = train_test_split(\n",
        "    X, y, seasons, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape, \"Test size:\", X_test.shape)\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=3,\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Clean\", \"Nutrient\", \"Bloom\", \"SparsePD\", \"DensePD\"],\n",
        "            yticklabels=[\"Clean\", \"Nutrient\", \"Bloom\", \"SparsePD\", \"DensePD\"])\n",
        "plt.title(\"Overall Confusion Matrix (All Years & Seasons)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Per-season confusion matrices\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "\n",
        "# Global font settings (optional)\n",
        "rcParams['font.weight'] = 'bold'\n",
        "rcParams['axes.labelweight'] = 'bold'\n",
        "rcParams['axes.titleweight'] = 'bold'\n",
        "\n",
        "CLASS_NAMES = [\"Clean\", \"Nutrient\", \"Bloom\", \"SparsePD\", \"DensePD\"]\n",
        "\n",
        "# Per-season confusion matrices\n",
        "unique_seasons_test = np.unique(seasons_test)\n",
        "\n",
        "for season in unique_seasons_test:\n",
        "    idx = np.where(seasons_test == season)\n",
        "    cm_s = confusion_matrix(y_test[idx], y_pred[idx])\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "\n",
        "    ax = sns.heatmap(\n",
        "        cm_s, annot=True, fmt=\"d\", cmap=\"viridis\",\n",
        "        xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
        "        annot_kws={\"size\": 16, \"weight\": \"bold\"}  # Bold annotation numbers\n",
        "    )\n",
        "\n",
        "    # Title\n",
        "    plt.title(f\"Confusion Matrix — {season}\", fontsize=20, fontweight='bold')\n",
        "\n",
        "    # Axis labels\n",
        "    plt.xlabel(\"Predicted\", fontsize=18, fontweight='bold')\n",
        "    plt.ylabel(\"Actual\", fontsize=18, fontweight='bold')\n",
        "\n",
        "    # Tick parameters\n",
        "    ax.tick_params(axis='both', labelsize=14, width=2, length=6)\n",
        "\n",
        "    # Make tick labels bold\n",
        "    for label in ax.get_xticklabels():\n",
        "        label.set_fontweight('bold')\n",
        "    for label in ax.get_yticklabels():\n",
        "        label.set_fontweight('bold')\n",
        "\n",
        "    # Colorbar formatting\n",
        "    cbar = ax.collections[0].colorbar\n",
        "    cbar.ax.tick_params(labelsize=14, width=2, length=6)\n",
        "    for label in cbar.ax.get_yticklabels():\n",
        "        label.set_fontweight('bold')\n",
        "    cbar.outline.set_linewidth(2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# MAP GENERATION WITH SAME OPTIONS\n",
        "# =====================================================\n",
        "def generate_classification_map(scene_path, model):\n",
        "    \"\"\"\n",
        "    Uses trained model to classify ONLY inside the lake shapefile,\n",
        "    saves GeoTIFF + PNG, and shows the plot.\n",
        "    \"\"\"\n",
        "    year, season, base = parse_scene_name(scene_path)\n",
        "    save_prefix = f\"ML_{year}_{season}\"\n",
        "\n",
        "    print(f\"\\n--- Generating classification map for {base} ---\")\n",
        "\n",
        "    stack, prof = read_stack_reflectance(scene_path)\n",
        "    n_bands, H, W = stack.shape\n",
        "\n",
        "    # Lake mask in this raster's grid\n",
        "    gdf_proj = gdf_lake.to_crs(prof[\"crs\"])\n",
        "    lake_mask = geometry_mask(\n",
        "        gdf_proj.geometry,\n",
        "        transform=prof[\"transform\"],\n",
        "        invert=True,\n",
        "        out_shape=(H, W)\n",
        "    )\n",
        "\n",
        "    B4 = stack[2]\n",
        "    B5 = stack[3]\n",
        "    B8 = stack[6]\n",
        "    eps = 1e-9\n",
        "\n",
        "    ndvi = (B8 - B4) / (B8 + B4 + eps)\n",
        "    ndci = (B5 - B4) / (B5 + B4 + eps)\n",
        "    chl  = 14.039 + 86.115 * ndci + 194.325 * (ndci ** 2)\n",
        "\n",
        "    flat_stack = stack.reshape(n_bands, -1).T\n",
        "    flat_ndvi  = ndvi.flatten()\n",
        "    flat_ndci  = ndci.flatten()\n",
        "    flat_chl   = chl.flatten()\n",
        "    flat_lake  = lake_mask.flatten()\n",
        "\n",
        "    X_scene_all = np.column_stack([flat_stack, flat_ndvi, flat_ndci, flat_chl])\n",
        "\n",
        "    # Predict ONLY inside lake\n",
        "    class_flat = np.full(H * W, 255, dtype=np.uint8)  # 255 = outside lake / nodata\n",
        "    idx_lake = np.where(flat_lake)[0]\n",
        "    if idx_lake.size > 0:\n",
        "        preds_lake = model.predict(X_scene_all[idx_lake])\n",
        "        class_flat[idx_lake] = preds_lake.astype(np.uint8)\n",
        "\n",
        "    class_map = class_flat.reshape(H, W)\n",
        "\n",
        "    # Save classification GeoTIFF\n",
        "    out_tif = f\"{save_prefix}_RF_Classification.tif\"\n",
        "    out_prof = prof.copy()\n",
        "    out_prof.update(\n",
        "        dtype=rasterio.uint8,\n",
        "        count=1,\n",
        "        nodata=255        # important: valid for uint8\n",
        "    )\n",
        "    with rasterio.open(out_tif, \"w\", **out_prof) as dst:\n",
        "        dst.write(class_map, 1)\n",
        "    print(f\"Saved GeoTIFF: {out_tif}\")\n",
        "\n",
        "    # Prepare for plotting: mask out 255 (outside lake)\n",
        "    plot_map = class_map.astype(float)\n",
        "    plot_map[plot_map == 255] = np.nan\n",
        "\n",
        "    # Discrete colormap for classes 0–4\n",
        "    cmap = mcolors.ListedColormap([\n",
        "        \"#1f78b4\",  # 0 Clean water\n",
        "        \"#33a02c\",  # 1 Nutrient-rich\n",
        "        \"#ff7f00\",  # 2 Bloom\n",
        "        \"#6a3d9a\",  # 3 Sparse phumdis\n",
        "        \"#e31a1c\"   # 4 Dense phumdis\n",
        "    ])\n",
        "    bounds = [-0.5, 0.5, 1.5, 2.5, 3.5, 4.5]\n",
        "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    im = plt.imshow(plot_map, cmap=cmap, norm=norm)\n",
        "    plt.title(f\"RF Ecosystem Classification — {year} {season}\", fontsize=14)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    cbar = plt.colorbar(im, boundaries=bounds, ticks=[0, 1, 2, 3, 4])\n",
        "    cbar.ax.set_yticklabels([\n",
        "        \"0 Clean water\",\n",
        "        \"1 Nutrient-rich\",\n",
        "        \"2 Bloom\",\n",
        "        \"3 Sparse phumdis\",\n",
        "        \"4 Dense phumdis\"\n",
        "    ], fontsize=9)\n",
        "\n",
        "    out_png = f\"{save_prefix}_RF_Classification.png\"\n",
        "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"Saved PNG: {out_png}\")\n",
        "\n",
        "    return class_map\n",
        "\n",
        "# Generate maps for all scenes\n",
        "for scene_path in scene_files:\n",
        "    generate_classification_map(scene_path, rf)\n",
        "\n",
        "\n",
        "# Per-season confusion matrices\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Global font settings (optional)\n",
        "rcParams['font.weight'] = 'bold'\n",
        "rcParams['axes.labelweight'] = 'bold'\n",
        "rcParams['axes.titleweight'] = 'bold'\n",
        "\n",
        "CLASS_NAMES = [\"Clean\", \"Nutrient\", \"Bloom\", \"SparsePD\", \"DensePD\"]\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(9, 7))\n",
        "ax = sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=CLASS_NAMES,\n",
        "    yticklabels=CLASS_NAMES,\n",
        "    annot_kws={\"size\": 16, \"weight\": \"bold\"}  # bold numbers in cells\n",
        ")\n",
        "\n",
        "# Title\n",
        "ax.set_title(\n",
        "    \"Overall Confusion Matrix (All Years & Seasons)\",\n",
        "    fontsize=20,\n",
        "    fontweight=\"bold\"\n",
        ")\n",
        "\n",
        "# Axis labels\n",
        "ax.set_xlabel(\"Predicted\", fontsize=18, fontweight=\"bold\")\n",
        "ax.set_ylabel(\"Actual\", fontsize=18, fontweight=\"bold\")\n",
        "\n",
        "# Tick style\n",
        "ax.tick_params(axis=\"both\", labelsize=14, width=2, length=6)\n",
        "for label in ax.get_xticklabels():\n",
        "    label.set_fontweight(\"bold\")\n",
        "for label in ax.get_yticklabels():\n",
        "    label.set_fontweight(\"bold\")\n",
        "\n",
        "# Colorbar formatting\n",
        "cbar = ax.collections[0].colorbar\n",
        "cbar.ax.tick_params(labelsize=14, width=2, length=6)\n",
        "for label in cbar.ax.get_yticklabels():\n",
        "    label.set_fontweight(\"bold\")\n",
        "cbar.outline.set_linewidth(2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "def generate_classification_map(scene_path, model):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import matplotlib.colors as mcolors\n",
        "    import matplotlib.image as mpimg\n",
        "    from pyproj import CRS, Transformer\n",
        "\n",
        "    year, season, base = parse_scene_name(scene_path)\n",
        "    save_prefix = f\"ML_{year}_{season}\"\n",
        "\n",
        "    print(f\"\\n--- Generating classification map for {base} ---\")\n",
        "\n",
        "    # ----------------------------\n",
        "    # LOAD & PREPARE DATA\n",
        "    # ----------------------------\n",
        "    stack, prof = read_stack_reflectance(scene_path)\n",
        "    n_bands, H, W = stack.shape\n",
        "\n",
        "    gdf_proj = gdf_lake.to_crs(prof[\"crs\"])\n",
        "    lake_mask = geometry_mask(\n",
        "        gdf_proj.geometry,\n",
        "        transform=prof[\"transform\"],\n",
        "        invert=True,\n",
        "        out_shape=(H, W)\n",
        "    )\n",
        "\n",
        "    B4 = stack[2]\n",
        "    B5 = stack[3]\n",
        "    B8 = stack[6]\n",
        "    eps = 1e-9\n",
        "\n",
        "    ndvi = (B8 - B4) / (B8 + B4 + eps)\n",
        "    ndci = (B5 - B4) / (B5 + B4 + eps)\n",
        "    chl  = 14.039 + 86.115 * ndci + 194.325 * (ndci ** 2)\n",
        "\n",
        "    # Flatten for prediction\n",
        "    flat_stack = stack.reshape(n_bands, -1).T\n",
        "    X_scene_all = np.column_stack([\n",
        "        flat_stack,\n",
        "        ndvi.flatten(),\n",
        "        ndci.flatten(),\n",
        "        chl.flatten()\n",
        "    ])\n",
        "    flat_lake = lake_mask.flatten()\n",
        "\n",
        "    # ----------------------------\n",
        "    # CLASSIFY\n",
        "    # ----------------------------\n",
        "    class_flat = np.full(H * W, 255, dtype=np.uint8)\n",
        "    idx_lake = np.where(flat_lake)[0]\n",
        "    if idx_lake.size > 0:\n",
        "        class_flat[idx_lake] = model.predict(X_scene_all[idx_lake]).astype(np.uint8)\n",
        "\n",
        "    class_map = class_flat.reshape(H, W)\n",
        "\n",
        "    # ----------------------------\n",
        "    # SAVE GEOTIFF\n",
        "    # ----------------------------\n",
        "    out_tif = f\"{save_prefix}_RF_Classification.tif\"\n",
        "    out_prof = prof.copy()\n",
        "    out_prof.update(dtype=rasterio.uint8, count=1, nodata=255)\n",
        "\n",
        "    with rasterio.open(out_tif, \"w\", **out_prof) as dst:\n",
        "        dst.write(class_map, 1)\n",
        "\n",
        "    print(f\"Saved GeoTIFF: {out_tif}\")\n",
        "\n",
        "    # ----------------------------\n",
        "    # PREP FOR PLOTTING\n",
        "    # ----------------------------\n",
        "    plot_map = class_map.astype(float)\n",
        "    plot_map[plot_map == 255] = np.nan  # outside lake\n",
        "\n",
        "    # Colors\n",
        "    cmap = mcolors.ListedColormap([\n",
        "        \"#1f78b4\",  # Clean\n",
        "        \"#33a02c\",  # Nutrient-rich\n",
        "        \"#ff7f00\",  # Bloom\n",
        "        \"#6a3d9a\",  # Sparse PD\n",
        "        \"#e31a1c\"   # Dense PD\n",
        "    ])\n",
        "    bounds = [-0.5, 0.5, 1.5, 2.5, 3.5, 4.5]\n",
        "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "    # ----------------------------\n",
        "    # GET LAT/LON EXTENT\n",
        "    # ----------------------------\n",
        "    h, w = class_map.shape\n",
        "    left, bottom, right, top = rasterio.transform.array_bounds(h, w, prof[\"transform\"])\n",
        "\n",
        "    try:\n",
        "        src_crs = CRS.from_user_input(prof[\"crs\"])\n",
        "        transformer = Transformer.from_crs(src_crs, CRS.from_epsg(4326), always_xy=True)\n",
        "        lon_left, lat_bottom = transformer.transform(left, bottom)\n",
        "        lon_right, lat_top   = transformer.transform(right, top)\n",
        "        extent = [lon_left, lon_right, lat_bottom, lat_top]\n",
        "        use_latlon = True\n",
        "    except:\n",
        "        extent = [left, right, bottom, top]\n",
        "        use_latlon = False\n",
        "\n",
        "    # ----------------------------\n",
        "    # FINAL PLOTTING (UPGRADED)\n",
        "    # ----------------------------\n",
        "    fig, ax = plt.subplots(figsize=(10, 10), dpi=500)\n",
        "\n",
        "    im = ax.imshow(plot_map, cmap=cmap, norm=norm,\n",
        "                   extent=extent, origin=\"upper\")\n",
        "\n",
        "    # TITLE\n",
        "    ax.set_title(\n",
        "        f\"Ecosystem Classification — {year} {season}\",\n",
        "        fontsize=22, fontweight=\"bold\"\n",
        "    )\n",
        "\n",
        "    # AXIS LABELS\n",
        "    if use_latlon:\n",
        "        ax.set_xlabel(\"Longitude\", fontsize=18, fontweight=\"bold\")\n",
        "        ax.set_ylabel(\"Latitude\", fontsize=18, fontweight=\"bold\")\n",
        "    else:\n",
        "        ax.set_xlabel(\"Easting\", fontsize=18, fontweight=\"bold\")\n",
        "        ax.set_ylabel(\"Northing\", fontsize=18, fontweight=\"bold\")\n",
        "\n",
        "    # TICKS (BOLD)\n",
        "    ax.tick_params(axis=\"both\", labelsize=15, width=2, length=6)\n",
        "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "        label.set_fontweight(\"bold\")\n",
        "\n",
        "    # COLORBAR (BOLD, LARGE)\n",
        "    cbar = plt.colorbar(im, boundaries=bounds, ticks=[0, 1, 2, 3, 4],\n",
        "                        fraction=0.035, pad=0.02)\n",
        "    cbar_labels = [\"Clean\", \"Nutrient-rich\", \"Bloom\", \"Sparse PD\", \"Dense PD\"]\n",
        "\n",
        "    cbar.ax.set_yticklabels(cbar_labels, fontsize=14, fontweight=\"bold\")\n",
        "    cbar.outline.set_linewidth(2)\n",
        "    cbar.ax.tick_params(width=2, length=6)\n",
        "\n",
        "    # NORTH ARROW (OPTIONAL)\n",
        "    try:\n",
        "        north_img = mpimg.imread(\"/content/drive/MyDrive/Pandas/Chl-a/Yearly Cliped_Data/Compass.jpg\")\n",
        "        ax_n = fig.add_axes([0.88, 0.86, 0.09, 0.09])\n",
        "        ax_n.imshow(north_img)\n",
        "        ax_n.axis(\"off\")\n",
        "    except:\n",
        "        print(\"Compass image not found — skipping.\")\n",
        "\n",
        "    # SAVE PNG\n",
        "    out_png = f\"{save_prefix}_RF_Classification.png\"\n",
        "    plt.savefig(out_png, dpi=400, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Saved PNG: {out_png}\")\n",
        "\n",
        "    return class_map\n",
        "\n",
        "# ==========================================\n",
        "# ROC–AUC (multiclass, one-vs-rest)\n",
        "# ==========================================\n",
        "# Note: This block is correctly placed outside the function.\n",
        "CLASS_NAMES = [\"Clean\", \"Nutrient\", \"Bloom\", \"SparsePD\", \"DensePD\"]\n",
        "n_classes = len(CLASS_NAMES)\n",
        "\n",
        "# 1) Get probability scores from RF\n",
        "y_score = rf.predict_proba(X_test)          # shape: (n_samples, n_classes)\n",
        "\n",
        "# 2) Binarize y_test for one-vs-rest ROC\n",
        "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3, 4])  # shape: (n_samples, n_classes)\n",
        "\n",
        "# 3) Compute ROC curve and AUC for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# 4) Macro-average ROC\n",
        "#    - Merge all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "#    - Interpolate all ROC curves at these points & average\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "print(f\"\\nMacro-average ROC–AUC: {roc_auc['macro']:.3f}\")\n",
        "\n",
        "# 5) Plot ROC curves (paper style)\n",
        "plt.figure(figsize=(8, 7), dpi=300)\n",
        "\n",
        "# Macro curve first (thicker)\n",
        "plt.plot(\n",
        "    fpr[\"macro\"],\n",
        "    tpr[\"macro\"],\n",
        "    label=f\"Macro-average (AUC = {roc_auc['macro']:.3f})\",\n",
        "    linewidth=3,\n",
        "    linestyle='-'\n",
        ")\n",
        "\n",
        "# Per-class curves\n",
        "colors = [\"#1f78b4\", \"#33a02c\", \"#ff7f00\", \"#6a3d9a\", \"#e31a1c\"]\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(\n",
        "        fpr[i], tpr[i],\n",
        "        lw=1.8,\n",
        "        label=f\"{CLASS_NAMES[i]} (AUC = {roc_auc[i]:.3f})\",\n",
        "        color=color\n",
        "    )\n",
        "\n",
        "# Diagonal no-skill line\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=1.2)\n",
        "\n",
        "# Axes limits\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "# Labels & title (bold)\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=16, fontweight=\"bold\")\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=16, fontweight=\"bold\")\n",
        "plt.title(\"Multiclass ROC Curves (RF – All Years & Seasons)\", fontsize=18, fontweight=\"bold\")\n",
        "\n",
        "# Ticks bold\n",
        "plt.xticks(fontsize=14, fontweight=\"bold\")\n",
        "plt.yticks(fontsize=14, fontweight=\"bold\")\n",
        "\n",
        "# Legend\n",
        "leg = plt.legend(loc=\"lower right\", fontsize=11)\n",
        "for text in leg.get_texts():\n",
        "    text.set_fontweight(\"bold\")\n",
        "\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JRwpac-7ZPSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN"
      ],
      "metadata": {
        "id": "qC_yjWkZZTGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from rasterio.features import geometry_mask\n",
        "import geopandas as gpd\n",
        "from skimage.morphology import dilation, disk\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                             accuracy_score, f1_score, precision_score,\n",
        "                             recall_score, roc_auc_score, roc_curve, auc,\n",
        "                             cohen_kappa_score, matthews_corrcoef)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# PyTorch imports\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    from torchvision import transforms\n",
        "except Exception as e:\n",
        "    raise ImportError(\"PyTorch not found. Install it first, e.g. `pip install torch torchvision`\") from e\n",
        "\n",
        "# ============================\n",
        "# USER: edit these paths & params\n",
        "# ============================\n",
        "SCENES_DIR = r\"/content/drive/MyDrive/Pandas/Chl-a/Yearly Cliped_Data/Ml_ AL season\"     # e.g. \"/content/drive/.../Ml_ AL season\"\n",
        "SHP_PATH   = r\"/content/drive/MyDrive/Pandas/Chl-a/Yearly Cliped_Data/SHP\"\n",
        "MAP_SAVE_DIR = r\"/content/drive/MyDrive/Pandas/Chl-a/CNN_Output\"\n",
        "MODEL_SAVE_DIR = r\"/content/drive/MyDrive/Pandas/Chl-a/CNN_Outputt\"\n",
        "EXCEL_SAVE_DIR = r\"/content/drive/MyDrive/Pandas/Chl-a/CNN_Output\"\n",
        "os.makedirs(MAP_SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(EXCEL_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "PATCH_SIZE = 9                    # odd (e.g., 5,7,9,11)\n",
        "SAMPLES_PER_CLASS_PER_SCENE = 500 # per scene (reduce if memory issues)\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "RANDOM_STATE = 42\n",
        "NUM_CLASSES = 5\n",
        "EXPECTED_BANDS = 11               # B2..B12\n",
        "SCALE_REFLECTANCE = True          # True if values are 0..10000\n",
        "BLOOM_PERCENTILE = 85             # to set CHL_T2\n",
        "CHL_T1_FIXED = 20.0               # clean vs nutrient threshold\n",
        "VEG_SPARSE = 0.20\n",
        "VEG_DENSE  = 0.40\n",
        "NDCI_BLOOM_MIN = 0.15\n",
        "NDVI_BLOOM_MIN = 0.25\n",
        "BLOOM_DILATE_RADIUS = 2\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "random.seed(RANDOM_STATE)\n",
        "np.random.seed(RANDOM_STATE)\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "\n",
        "# ============================\n",
        "# Helper: read stack reflectance\n",
        "# ============================\n",
        "def read_stack_reflectance(path):\n",
        "    \"\"\"Read stacked multi-band GeoTIFF (bands x H x W). Convert to float32 reflectance 0..1 if needed.\"\"\"\n",
        "    with rasterio.open(path) as src:\n",
        "        arr = src.read().astype(\"float32\")  # shape (bands, H, W)\n",
        "        prof = src.profile.copy()\n",
        "    finite = np.isfinite(arr)\n",
        "    if SCALE_REFLECTANCE and finite.any() and float(np.nanmax(arr[finite])) > 1.5:\n",
        "        arr = np.where(finite, arr / 10000.0, np.nan)\n",
        "    arr = np.clip(arr, 0.0, 1.5)\n",
        "    return arr, prof\n",
        "\n",
        "# ============================\n",
        "# Helper: parse scene file name\n",
        "# ============================\n",
        "def parse_scene_name(path):\n",
        "    base = os.path.basename(path).replace(\".tif\",\"\")\n",
        "    parts = base.split(\"_\",1)\n",
        "    if len(parts)==2:\n",
        "        year, season = parts\n",
        "    else:\n",
        "        year, season = \"Unknown\", base\n",
        "    return year, season, base\n",
        "\n",
        "# ============================\n",
        "# Helper: compute class map (same rules as RF pipeline)\n",
        "# ============================\n",
        "def build_classes_from_stack(stack, lake_mask, CHL_T1, CHL_T2):\n",
        "    # stack: (bands, H, W); expects RE1 at index 3, Red at index 2, NIR at index 6 if B2..B12\n",
        "    B2 = stack[0]; B3 = stack[1]; B4 = stack[2]; B5 = stack[3]; B8 = stack[6]\n",
        "    eps = 1e-9\n",
        "    ndvi = (B8 - B4) / (B8 + B4 + eps)\n",
        "    ndci = (B5 - B4) / (B5 + B4 + eps)\n",
        "    chl = 14.039 + 86.115 * ndci + 194.325 * (ndci ** 2)\n",
        "    H,W = B4.shape\n",
        "    class_map = np.full((H,W), np.nan, dtype=\"float32\")\n",
        "\n",
        "    dense  = (ndvi >= VEG_DENSE) & lake_mask\n",
        "    sparse = (ndvi >= VEG_SPARSE) & (ndvi < VEG_DENSE) & lake_mask\n",
        "    water  = (ndvi < VEG_SPARSE) & lake_mask\n",
        "\n",
        "    class_map[dense]  = 4\n",
        "    class_map[sparse] = 3\n",
        "\n",
        "    bloom_core = (chl >= CHL_T2) & water\n",
        "    bloom_spectral = ((ndci > NDCI_BLOOM_MIN) & (ndvi > NDVI_BLOOM_MIN)) & water\n",
        "    bloom = bloom_core | bloom_spectral\n",
        "    if BLOOM_DILATE_RADIUS > 0:\n",
        "        bloom = dilation(bloom, disk(BLOOM_DILATE_RADIUS)) & water\n",
        "    class_map[bloom] = 2\n",
        "\n",
        "    water_remain = water & (~bloom)\n",
        "    class_map[(chl < CHL_T1) & water_remain] = 0\n",
        "    class_map[(chl >= CHL_T1) & water_remain] = 1\n",
        "\n",
        "    return class_map, chl, ndvi, ndci\n",
        "\n",
        "# ============================\n",
        "# PASS 1: scan scenes to collect CHL percentiles -> CHL_T2\n",
        "# ============================\n",
        "scene_files = sorted(glob.glob(os.path.join(SCENES_DIR, \"*.tif\")))\n",
        "if len(scene_files)==0:\n",
        "    raise RuntimeError(\"No .tif scenes found in SCENES_DIR. Edit SCENES_DIR path.\")\n",
        "\n",
        "gdf_lake = gpd.read_file(SHP_PATH)\n",
        "print(\"Found scenes:\", len(scene_files), \"Shapefile rows:\", len(gdf_lake))\n",
        "\n",
        "all_chl = []\n",
        "for scene_path in scene_files:\n",
        "    print(\"Collecting chl from:\", os.path.basename(scene_path))\n",
        "    stack, prof = read_stack_reflectance(scene_path)\n",
        "    H = stack.shape[1]; W = stack.shape[2]\n",
        "    gdf_proj = gdf_lake.to_crs(prof['crs'])\n",
        "    lake_mask = geometry_mask(gdf_proj.geometry, transform=prof['transform'], invert=True, out_shape=(H,W))\n",
        "    _, chl, _, _ = build_classes_from_stack(stack, lake_mask, CHL_T1_FIXED, CHL_T1_FIXED+10)  # CHL_T2 placeholder\n",
        "    valid = lake_mask & np.isfinite(chl)\n",
        "    if np.any(valid):\n",
        "        all_chl.append(chl[valid])\n",
        "if len(all_chl)==0:\n",
        "    raise RuntimeError(\"No valid chl values inside lake for any scene.\")\n",
        "all_chl = np.concatenate(all_chl)\n",
        "p50,p75,p85,p90,p95 = np.percentile(all_chl, [50,75,85,90,95])\n",
        "CHL_T1 = CHL_T1_FIXED\n",
        "CHL_T2 = float(np.percentile(all_chl, BLOOM_PERCENTILE))\n",
        "print(f\"Chl percentiles: 50%={p50:.2f},75%={p75:.2f},85%={p85:.2f},90%={p90:.2f},95%={p95:.2f}\")\n",
        "print(f\"Using CHL_T1={CHL_T1:.2f}, CHL_T2({BLOOM_PERCENTILE}th)={CHL_T2:.2f}\")\n",
        "\n",
        "# ============================\n",
        "# Patch extraction functions\n",
        "# ============================\n",
        "def extract_patches_from_scene(stack, class_map, lake_mask, patch_size=9, samples_per_class=500):\n",
        "    half = patch_size//2\n",
        "    bands, H, W = stack.shape\n",
        "    pad_width = ((0,0),(half,half),(half,half))\n",
        "    stack_p = np.pad(stack, pad_width=pad_width, mode='reflect')\n",
        "    X = []\n",
        "    y = []\n",
        "    flat_cls = class_map.flatten()\n",
        "    flat_lake = lake_mask.flatten()\n",
        "    for cls in range(NUM_CLASSES):\n",
        "        idxs = np.where((flat_cls==cls) & (flat_lake))[0]\n",
        "        if idxs.size==0:\n",
        "            continue\n",
        "        # sample up to requested\n",
        "        sel = idxs if idxs.size <= samples_per_class else np.random.choice(idxs, samples_per_class, replace=False)\n",
        "        for ind in sel:\n",
        "            r = ind // W; c = ind % W\n",
        "            rp = r + half; cp = c + half\n",
        "            patch = stack_p[:, rp-half:rp+half+1, cp-half:cp+half+1]\n",
        "            patch = np.transpose(patch, (1,2,0))  # (p,p,bands)\n",
        "            X.append(patch)\n",
        "            y.append(cls)\n",
        "    if len(X)==0:\n",
        "        return np.empty((0,patch_size,patch_size,bands)), np.empty((0,), dtype=int)\n",
        "    X = np.stack(X, axis=0).astype('float32')\n",
        "    y = np.array(y, dtype=int)\n",
        "    return X,y\n",
        "\n",
        "def build_dataset_from_scenes(scene_files, gdf_lake, patch_size=9, samples_per_class=500):\n",
        "    X_list=[]; y_list=[]\n",
        "    for scene_path in scene_files:\n",
        "        print(\"Scene:\", os.path.basename(scene_path))\n",
        "        stack, prof = read_stack_reflectance(scene_path)\n",
        "        H = stack.shape[1]; W = stack.shape[2]\n",
        "        gdf_proj = gdf_lake.to_crs(prof['crs'])\n",
        "        lake_mask = geometry_mask(gdf_proj.geometry, transform=prof['transform'], invert=True, out_shape=(H,W))\n",
        "        class_map, chl, ndvi, ndci = build_classes_from_stack(stack, lake_mask, CHL_T1, CHL_T2)\n",
        "        Xp, yp = extract_patches_from_scene(stack, class_map, lake_mask, patch_size=patch_size, samples_per_class=samples_per_class)\n",
        "        if Xp.shape[0]>0:\n",
        "            X_list.append(Xp); y_list.append(yp)\n",
        "    if not X_list:\n",
        "        raise RuntimeError(\"No patches extracted from scenes. Check masks/thresholds.\")\n",
        "    X_all = np.concatenate(X_list, axis=0)\n",
        "    y_all = np.concatenate(y_list, axis=0)\n",
        "    print(\"Patches total:\", X_all.shape, \"Label counts:\", np.unique(y_all, return_counts=True))\n",
        "    return X_all, y_all\n",
        "\n",
        "# ============================\n",
        "# Build dataset (patches)\n",
        "# ============================\n",
        "X, y = build_dataset_from_scenes(scene_files, gdf_lake, patch_size=PATCH_SIZE, samples_per_class=SAMPLES_PER_CLASS_PER_SCENE)\n",
        "\n",
        "# If bands != expected, warn (but continue)\n",
        "bands_found = X.shape[-1]\n",
        "if bands_found != EXPECTED_BANDS:\n",
        "    print(f\"Warning: patches have {bands_found} bands (EXPECTED_BANDS={EXPECTED_BANDS}). If order differs, update code.\")\n",
        "\n",
        "# Train/val/test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=RANDOM_STATE, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp)\n",
        "print(\"Train/Val/Test sizes:\", X_train.shape[0], X_val.shape[0], X_test.shape[0])\n",
        "\n",
        "# ============================\n",
        "# PyTorch Dataset & Dataloader\n",
        "# ============================\n",
        "class PatchDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]  # (p,p,bands)\n",
        "        # transpose to (bands, p, p) for PyTorch\n",
        "        x = np.transpose(x, (2,0,1)).astype('float32')\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        y = int(self.y[idx])\n",
        "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "train_ds = PatchDataset(X_train, y_train)\n",
        "val_ds   = PatchDataset(X_val, y_val)\n",
        "test_ds  = PatchDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "# ============================\n",
        "# Compute class weights for loss\n",
        "# ============================\n",
        "cls_vals = np.unique(y_train)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=cls_vals, y=y_train)\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32).to(DEVICE)\n",
        "print(\"Class weights:\", dict(zip(cls_vals, weights)))\n",
        "\n",
        "# ============================\n",
        "# Define CNN model (PyTorch)\n",
        "# ============================\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.drop1 = nn.Dropout2d(0.25)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64,128,kernel_size=3,padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128,128,kernel_size=3,padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.drop2 = nn.Dropout2d(0.35)\n",
        "\n",
        "        # global pool\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(128, 256)\n",
        "        self.bnfc = nn.BatchNorm1d(256)\n",
        "        self.dropfc = nn.Dropout(0.4)\n",
        "        self.out = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.drop2(x)\n",
        "\n",
        "        x = self.gap(x)   # shape (B,128,1,1)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.bnfc(self.fc1(x)))\n",
        "        x = self.dropfc(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN(in_channels=bands_found, num_classes=NUM_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# ============================\n",
        "# Training loop (simple early stopping)\n",
        "# ============================\n",
        "best_val_acc = 0.0\n",
        "patience = 6\n",
        "patience_counter = 0\n",
        "history = {\"train_loss\":[], \"val_loss\":[], \"train_acc\":[], \"val_acc\":[]}\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running_loss = 0.0; correct=0; total=0\n",
        "    for xb, yb in train_loader:\n",
        "        xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "        preds = out.argmax(dim=1)\n",
        "        correct += (preds==yb).sum().item()\n",
        "        total += xb.size(0)\n",
        "    train_loss = running_loss/total\n",
        "    train_acc = correct/total\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    vloss=0.0; vcorrect=0; vtotal=0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb=xb.to(DEVICE); yb=yb.to(DEVICE)\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            vloss += loss.item() * xb.size(0)\n",
        "            preds = out.argmax(dim=1)\n",
        "            vcorrect += (preds==yb).sum().item()\n",
        "            vtotal += xb.size(0)\n",
        "    val_loss = vloss/vtotal\n",
        "    val_acc = vcorrect/vtotal\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{EPOCHS}  train_loss={train_loss:.4f} train_acc={train_acc:.4f}  val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
        "\n",
        "    # early stopping & save best\n",
        "    if val_acc > best_val_acc + 1e-5:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, \"cnn_best.pth\"))\n",
        "        patience_counter = 0\n",
        "        print(\"  Saved best model.\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "# load best\n",
        "model.load_state_dict(torch.load(os.path.join(MODEL_SAVE_DIR, \"cnn_best.pth\"), map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "# ============================\n",
        "# Evaluate on test set\n",
        "# ============================\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_proba = []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        out = model(xb)\n",
        "        probs = F.softmax(out, dim=1).cpu().numpy()\n",
        "        preds = out.argmax(dim=1).cpu().numpy()\n",
        "        y_true.extend(yb.numpy().tolist())\n",
        "        y_pred.extend(preds.tolist())\n",
        "        y_proba.extend(probs.tolist())\n",
        "y_true = np.array(y_true); y_pred = np.array(y_pred); y_proba = np.vstack(y_proba)\n",
        "\n",
        "# Metrics\n",
        "acc  = accuracy_score(y_true, y_pred)\n",
        "f1_m = f1_score(y_true, y_pred, average='macro')\n",
        "f1_w = f1_score(y_true, y_pred, average='weighted')\n",
        "prec = precision_score(y_true, y_pred, average='macro')\n",
        "rec  = recall_score(y_true, y_pred, average='macro')\n",
        "kappa = cohen_kappa_score(y_true, y_pred)\n",
        "mcc = matthews_corrcoef(y_true, y_pred)\n",
        "roc_macro = roc_auc_score(label_binarize(y_true, classes=list(range(NUM_CLASSES))), y_proba, multi_class='ovr', average='macro')\n",
        "\n",
        "print(\"\\n=== CNN Test-set Performance ===\")\n",
        "print(f\"Accuracy          : {acc:.3f}\")\n",
        "print(f\"F1-score (macro)  : {f1_m:.3f}\")\n",
        "print(f\"F1-score (weighted): {f1_w:.3f}\")\n",
        "print(f\"Precision (macro) : {prec:.3f}\")\n",
        "print(f\"Recall (macro)    : {rec:.3f}\")\n",
        "print(f\"Cohen's Kappa     : {kappa:.3f}\")\n",
        "print(f\"MCC               : {mcc:.3f}\")\n",
        "print(f\"ROC–AUC (macro)   : {roc_macro:.3f}\")\n",
        "\n",
        "print(\"\\nClassification Report (per class):\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Clean\",\"Nutrient\",\"Bloom\",\"SparsePD\",\"DensePD\"]))\n",
        "\n",
        "# ============================\n",
        "# Save performance to Excel\n",
        "# ============================\n",
        "summary_metrics = {\n",
        "    \"Model\": [\"CNN\"],\n",
        "    \"Accuracy\": [acc],\n",
        "    \"F1_macro\": [f1_m],\n",
        "    \"F1_weighted\": [f1_w],\n",
        "    \"Precision_macro\": [prec],\n",
        "    \"Recall_macro\": [rec],\n",
        "    \"Cohen_Kappa\": [kappa],\n",
        "    \"MCC\": [mcc],\n",
        "    \"ROC_AUC_macro\": [roc_macro]\n",
        "}\n",
        "df_summary = pd.DataFrame(summary_metrics)\n",
        "df_per_class = pd.DataFrame(classification_report(y_true, y_pred, target_names=[\"Clean\",\"Nutrient\",\"Bloom\",\"SparsePD\",\"DensePD\"], output_dict=True)).transpose()\n",
        "\n",
        "excel_out = os.path.join(EXCEL_SAVE_DIR, \"CNN_Performance_Metrics.xlsx\")\n",
        "with pd.ExcelWriter(excel_out, engine=\"openpyxl\") as writer:\n",
        "    df_summary.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    df_per_class.to_excel(writer, sheet_name=\"Per_Class\")\n",
        "print(\"Saved performance Excel to:\", excel_out)\n",
        "\n",
        "# ============================\n",
        "# Styled confusion matrix (with cell lines)\n",
        "# ============================\n",
        "CLASS_NAMES = [\"Clean\",\"Nutrient\",\"Bloom\",\"SparsePD\",\"DensePD\"]\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(9,7))\n",
        "ax = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                 xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
        "                 annot_kws={\"size\":16, \"weight\":\"bold\"},\n",
        "                 linewidths=2, linecolor=\"black\")\n",
        "ax.set_title(\"CNN — Confusion Matrix (Test)\", fontsize=20, fontweight=\"bold\")\n",
        "ax.set_xlabel(\"Predicted\", fontsize=18, fontweight=\"bold\"); ax.set_ylabel(\"Actual\", fontsize=18, fontweight=\"bold\")\n",
        "ax.tick_params(axis=\"both\", labelsize=14, width=2, length=6)\n",
        "for lbl in ax.get_xticklabels()+ax.get_yticklabels(): lbl.set_fontweight(\"bold\")\n",
        "cbar = ax.collections[0].colorbar; cbar.ax.tick_params(labelsize=14); cbar.outline.set_linewidth(2)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MAP_SAVE_DIR, \"CNN_Confusion_Matrix.png\"), dpi=600, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ============================\n",
        "# ROC curves plot (multiclass)\n",
        "# ============================\n",
        "n_classes = NUM_CLASSES\n",
        "y_bin = label_binarize(y_true, classes=list(range(n_classes)))\n",
        "fpr = dict(); tpr = dict(); roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_bin[:,i], y_proba[:,i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "mean_tpr /= n_classes\n",
        "fpr[\"macro\"] = all_fpr; tpr[\"macro\"] = mean_tpr; roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "plt.figure(figsize=(9,8), dpi=300)\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f\"Macro-average (AUC = {roc_auc['macro']:.3f})\", linewidth=4, color=\"black\")\n",
        "line_styles = [\"-\", \"--\", \"-.\", \":\", (0,(3,1,1,1))]\n",
        "colors = [\"#1f78b4\",\"#33a02c\",\"#ff7f00\",\"#6a3d9a\",\"#e31a1c\"]\n",
        "for i,(ls,color) in enumerate(zip(line_styles, colors)):\n",
        "    plt.plot(fpr[i], tpr[i], lw=2.5, linestyle=ls, color=color, label=f\"{CLASS_NAMES[i]} (AUC={roc_auc[i]:.3f})\")\n",
        "plt.plot([0,1],[0,1],'k--', lw=1.5)\n",
        "plt.xlim([0,1]); plt.ylim([0,1.05])\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=18, fontweight=\"bold\")\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=18, fontweight=\"bold\")\n",
        "plt.title(\"CNN — Multiclass ROC Curves\", fontsize=20, fontweight=\"bold\")\n",
        "plt.xticks(fontsize=14); plt.yticks(fontsize=14)\n",
        "leg = plt.legend(loc=\"lower right\", fontsize=12)\n",
        "for t in leg.get_texts(): t.set_fontweight(\"bold\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MAP_SAVE_DIR, \"CNN_ROC_Curves.png\"), dpi=600, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ============================\n",
        "# Predict and save classification maps per scene (batch-patch prediction)\n",
        "# ============================\n",
        "def predict_map_with_cnn(scene_path, model, patch_size=PATCH_SIZE, batch_size=4096, save_dir=MAP_SAVE_DIR):\n",
        "    year, season, base = parse_scene_name(scene_path)\n",
        "    stack, prof = read_stack_reflectance(scene_path)\n",
        "    bands, H, W = stack.shape\n",
        "    gdf_proj = gdf_lake.to_crs(prof['crs'])\n",
        "    lake_mask = geometry_mask(gdf_proj.geometry, transform=prof['transform'], invert=True, out_shape=(H,W))\n",
        "\n",
        "    half = patch_size//2\n",
        "    pad_width = ((0,0),(half,half),(half,half))\n",
        "    stack_p = np.pad(stack, pad_width=pad_width, mode='reflect')\n",
        "    class_flat = np.full(H*W, 255, dtype=np.uint8)\n",
        "    idx_lake = np.where(lake_mask.flatten())[0]\n",
        "    print(\"Predicting for lake pixels:\", idx_lake.size)\n",
        "    n = idx_lake.size\n",
        "    for i in range(0, n, batch_size):\n",
        "        sel = idx_lake[i:i+batch_size]\n",
        "        patches = []\n",
        "        for ind in sel:\n",
        "            r = ind // W; c = ind % W\n",
        "            rp = r + half; cp = c + half\n",
        "            p = stack_p[:, rp-half:rp+half+1, cp-half:cp+half+1]\n",
        "            p = np.transpose(p, (1,2,0)).astype('float32')\n",
        "            patches.append(p)\n",
        "        Xb = np.stack(patches, axis=0)\n",
        "        Xb_t = torch.from_numpy(np.transpose(Xb, (0,3,1,2))).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            out = model(Xb_t)\n",
        "            probs = F.softmax(out, dim=1).cpu().numpy()\n",
        "            preds = probs.argmax(axis=1).astype(np.uint8)\n",
        "        class_flat[sel] = preds\n",
        "    class_map = class_flat.reshape(H,W)\n",
        "\n",
        "    # save GeoTIFF\n",
        "    out_tif = os.path.join(save_dir, f\"{year}_{season}_CNN_Map.tif\")\n",
        "    prof2 = prof.copy(); prof2.update(dtype=rasterio.uint8, count=1, nodata=255)\n",
        "    with rasterio.open(out_tif, \"w\", **prof2) as dst:\n",
        "        dst.write(class_map, 1)\n",
        "    print(\"Saved CNN GeoTIFF:\", out_tif)\n",
        "\n",
        "    # save PNG (clean map only)\n",
        "    plot_map = class_map.astype(float); plot_map[plot_map==255]=np.nan\n",
        "    cmap = mcolors.ListedColormap(colors)\n",
        "    bounds = [-0.5,0.5,1.5,2.5,3.5,4.5]; norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
        "    fig, ax = plt.subplots(figsize=(10,10), dpi=300)\n",
        "    ax.imshow(plot_map, cmap=cmap, norm=norm, origin='upper')\n",
        "    ax.set_title(f\"{year} {season} (CNN)\", fontsize=22, fontweight='bold')\n",
        "    ax.axis('off')\n",
        "    out_png = os.path.join(save_dir, f\"{year}_{season}_CNN_Map.png\")\n",
        "    fig.savefig(out_png, dpi=400, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"Saved CNN PNG:\", out_png)\n",
        "    return class_map\n",
        "\n",
        "# run prediction maps for all scenes\n",
        "for scene in scene_files:\n",
        "    predict_map_with_cnn(scene, model, patch_size=PATCH_SIZE, batch_size=4096, save_dir=MAP_SAVE_DIR)\n",
        "\n",
        "print(\"All done. Maps in:\", MAP_SAVE_DIR)\n",
        "print(\"Models in:\", MODEL_SAVE_DIR)\n",
        "print(\"Excel in:\", EXCEL_SAVE_DIR)\n"
      ],
      "metadata": {
        "id": "A8ThxETEZX-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3D CNN"
      ],
      "metadata": {
        "id": "Wb-DoTdYZa9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full runnable cell: 3D CNN pipeline for Sentinel-2 patch classification\n",
        "# Edit paths and parameters below before running.\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from rasterio.features import geometry_mask\n",
        "import geopandas as gpd\n",
        "from skimage.morphology import dilation, disk\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                             accuracy_score, f1_score, precision_score,\n",
        "                             recall_score, roc_auc_score, roc_curve, auc,\n",
        "                             cohen_kappa_score, matthews_corrcoef)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# PyTorch imports\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    from torchvision import transforms\n",
        "except Exception as e:\n",
        "    raise ImportError(\"PyTorch not found. Install it first, e.g. `pip install torch torchvision`\") from e\n",
        "\n",
        "# ============================\n",
        "# USER: edit these paths & params\n",
        "# ============================\n",
        "SCENES_DIR = r\"/content/drive/MyDrive/_ AL season\"     # e.g. \"/content/drive/.../Ml_ AL season\"\n",
        "SHP_PATH   = r\"/content/drive/MyDrive/HP\"\n",
        "MAP_SAVE_DIR = r\"/content/drive/MyDrive/t\"\n",
        "MODEL_SAVE_DIR = r\"/content/drive/MyDrive/Pandas/t\"\n",
        "EXCEL_SAVE_DIR = r\"/content/drive/MyDrive/Pandas/t\"\n",
        "os.makedirs(MAP_SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(EXCEL_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "PATCH_SIZE = 9                    # odd (e.g., 5,7,9,11)\n",
        "SAMPLES_PER_CLASS_PER_SCENE = 500 # per scene (reduce if memory issues)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "RANDOM_STATE = 42\n",
        "NUM_CLASSES = 5\n",
        "# Set expected bands according to your stacked TIFF order. For B2,B3,B4,B5,B6,B7,B8,B8A,B11,B12 -> 10 bands\n",
        "EXPECTED_BANDS = 10\n",
        "SCALE_REFLECTANCE = True          # True if values are 0..10000 in TIFF\n",
        "BLOOM_PERCENTILE = 85             # to set CHL_T2\n",
        "CHL_T1_FIXED = 20.0               # clean vs nutrient threshold\n",
        "VEG_SPARSE = 0.20\n",
        "VEG_DENSE  = 0.40\n",
        "NDCI_BLOOM_MIN = 0.15\n",
        "NDVI_BLOOM_MIN = 0.25\n",
        "BLOOM_DILATE_RADIUS = 2\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "random.seed(RANDOM_STATE)\n",
        "np.random.seed(RANDOM_STATE)\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "\n",
        "# color palette used for plotting & map (five classes)\n",
        "CLASS_NAMES = [\"Clean\",\"Nutrient\",\"Bloom\",\"SparsePD\",\"DensePD\"]\n",
        "PLOT_COLORS = [\"#1f78b4\",\"#33a02c\",\"#ff7f00\",\"#6a3d9a\",\"#e31a1c\"]\n",
        "\n",
        "# ============================\n",
        "# Helper: read stack reflectance\n",
        "# ============================\n",
        "def read_stack_reflectance(path):\n",
        "    \"\"\"Read stacked multi-band GeoTIFF (bands x H x W). Convert to float32 reflectance 0..1 if needed.\"\"\"\n",
        "    with rasterio.open(path) as src:\n",
        "        arr = src.read().astype(\"float32\")  # shape (bands, H, W)\n",
        "        prof = src.profile.copy()\n",
        "    finite = np.isfinite(arr)\n",
        "    if SCALE_REFLECTANCE and finite.any() and float(np.nanmax(arr[finite])) > 1.5:\n",
        "        arr = np.where(finite, arr / 10000.0, np.nan)\n",
        "    arr = np.clip(arr, 0.0, 1.5)\n",
        "    return arr, prof\n",
        "\n",
        "# ============================\n",
        "# Helper: parse scene file name\n",
        "# ============================\n",
        "def parse_scene_name(path):\n",
        "    base = os.path.basename(path).replace(\".tif\",\"\")\n",
        "    parts = base.split(\"_\",1)\n",
        "    if len(parts)==2:\n",
        "        year, season = parts\n",
        "    else:\n",
        "        year, season = \"Unknown\", base\n",
        "    return year, season, base\n",
        "\n",
        "# ============================\n",
        "# Helper: compute class map (same rules as RF pipeline)\n",
        "# ============================\n",
        "def build_classes_from_stack(stack, lake_mask, CHL_T1, CHL_T2):\n",
        "    # stack: (bands, H, W); expects B2 index 0, B3 index 1, B4 index 2, B5 index 3, B8 index 6 for the standard ordering used earlier\n",
        "    # Adjust indexes here if your band order differs.\n",
        "    B2 = stack[0]; B3 = stack[1]; B4 = stack[2]; B5 = stack[3]; B8 = stack[6]\n",
        "    eps = 1e-9\n",
        "    ndvi = (B8 - B4) / (B8 + B4 + eps)\n",
        "    ndci = (B5 - B4) / (B5 + B4 + eps)\n",
        "    # empirical chlorophyll estimation (same formula you used)\n",
        "    chl = 14.039 + 86.115 * ndci + 194.325 * (ndci ** 2)\n",
        "    H,W = B4.shape\n",
        "    class_map = np.full((H,W), np.nan, dtype=\"float32\")\n",
        "\n",
        "    dense  = (ndvi >= VEG_DENSE) & lake_mask\n",
        "    sparse = (ndvi >= VEG_SPARSE) & (ndvi < VEG_DENSE) & lake_mask\n",
        "    water  = (ndvi < VEG_SPARSE) & lake_mask\n",
        "\n",
        "    class_map[dense]  = 4\n",
        "    class_map[sparse] = 3\n",
        "\n",
        "    bloom_core = (chl >= CHL_T2) & water\n",
        "    bloom_spectral = ((ndci > NDCI_BLOOM_MIN) & (ndvi > NDVI_BLOOM_MIN)) & water\n",
        "    bloom = bloom_core | bloom_spectral\n",
        "    if BLOOM_DILATE_RADIUS > 0:\n",
        "        bloom = dilation(bloom, disk(BLOOM_DILATE_RADIUS)) & water\n",
        "    class_map[bloom] = 2\n",
        "\n",
        "    water_remain = water & (~bloom)\n",
        "    class_map[(chl < CHL_T1) & water_remain] = 0\n",
        "    class_map[(chl >= CHL_T1) & water_remain] = 1\n",
        "\n",
        "    return class_map, chl, ndvi, ndci\n",
        "\n",
        "# ============================\n",
        "# PASS 1: scan scenes to collect CHL percentiles -> CHL_T2\n",
        "# ============================\n",
        "scene_files = sorted(glob.glob(os.path.join(SCENES_DIR, \"*.tif\")))\n",
        "if len(scene_files)==0:\n",
        "    raise RuntimeError(\"No .tif scenes found in SCENES_DIR. Edit SCENES_DIR path.\")\n",
        "\n",
        "gdf_lake = gpd.read_file(SHP_PATH)\n",
        "print(\"Found scenes:\", len(scene_files), \"Shapefile rows:\", len(gdf_lake))\n",
        "\n",
        "all_chl = []\n",
        "for scene_path in scene_files:\n",
        "    print(\"Collecting chl from:\", os.path.basename(scene_path))\n",
        "    stack, prof = read_stack_reflectance(scene_path)\n",
        "    H = stack.shape[1]; W = stack.shape[2]\n",
        "    gdf_proj = gdf_lake.to_crs(prof['crs'])\n",
        "    lake_mask = geometry_mask(gdf_proj.geometry, transform=prof['transform'], invert=True, out_shape=(H,W))\n",
        "    _, chl, _, _ = build_classes_from_stack(stack, lake_mask, CHL_T1_FIXED, CHL_T1_FIXED+10)  # CHL_T2 placeholder\n",
        "    valid = lake_mask & np.isfinite(chl)\n",
        "    if np.any(valid):\n",
        "        all_chl.append(chl[valid])\n",
        "if len(all_chl)==0:\n",
        "    raise RuntimeError(\"No valid chl values inside lake for any scene.\")\n",
        "all_chl = np.concatenate(all_chl)\n",
        "p50,p75,p85,p90,p95 = np.percentile(all_chl, [50,75,85,90,95])\n",
        "CHL_T1 = CHL_T1_FIXED\n",
        "CHL_T2 = float(np.percentile(all_chl, BLOOM_PERCENTILE))\n",
        "print(f\"Chl percentiles: 50%={p50:.2f},75%={p75:.2f},85%={p85:.2f},90%={p90:.2f},95%={p95:.2f}\")\n",
        "print(f\"Using CHL_T1={CHL_T1:.2f}, CHL_T2({BLOOM_PERCENTILE}th)={CHL_T2:.2f}\")\n",
        "\n",
        "# ============================\n",
        "# Patch extraction functions\n",
        "# ============================\n",
        "def extract_patches_from_scene(stack, class_map, lake_mask, patch_size=9, samples_per_class=500):\n",
        "    half = patch_size//2\n",
        "    bands, H, W = stack.shape\n",
        "    pad_width = ((0,0),(half,half),(half,half))\n",
        "    stack_p = np.pad(stack, pad_width=pad_width, mode='reflect')\n",
        "    X = []\n",
        "    y = []\n",
        "    flat_cls = class_map.flatten()\n",
        "    flat_lake = lake_mask.flatten()\n",
        "    for cls in range(NUM_CLASSES):\n",
        "        idxs = np.where((flat_cls==cls) & (flat_lake))[0]\n",
        "        if idxs.size==0:\n",
        "            continue\n",
        "        # sample up to requested\n",
        "        sel = idxs if idxs.size <= samples_per_class else np.random.choice(idxs, samples_per_class, replace=False)\n",
        "        for ind in sel:\n",
        "            r = ind // W; c = ind % W\n",
        "            rp = r + half; cp = c + half\n",
        "            patch = stack_p[:, rp-half:rp+half+1, cp-half:cp+half+1]\n",
        "            patch = np.transpose(patch, (1,2,0))  # (p,p,bands)\n",
        "            X.append(patch)\n",
        "            y.append(cls)\n",
        "    if len(X)==0:\n",
        "        return np.empty((0,patch_size,patch_size,bands)), np.empty((0,), dtype=int)\n",
        "    X = np.stack(X, axis=0).astype('float32')\n",
        "    y = np.array(y, dtype=int)\n",
        "    return X,y\n",
        "\n",
        "def build_dataset_from_scenes(scene_files, gdf_lake, patch_size=9, samples_per_class=500):\n",
        "    X_list=[]; y_list=[]\n",
        "    for scene_path in scene_files:\n",
        "        print(\"Scene:\", os.path.basename(scene_path))\n",
        "        stack, prof = read_stack_reflectance(scene_path)\n",
        "        H = stack.shape[1]; W = stack.shape[2]\n",
        "        gdf_proj = gdf_lake.to_crs(prof['crs'])\n",
        "        lake_mask = geometry_mask(gdf_proj.geometry, transform=prof['transform'], invert=True, out_shape=(H,W))\n",
        "        class_map, chl, ndvi, ndci = build_classes_from_stack(stack, lake_mask, CHL_T1, CHL_T2)\n",
        "        Xp, yp = extract_patches_from_scene(stack, class_map, lake_mask, patch_size=patch_size, samples_per_class=samples_per_class)\n",
        "        if Xp.shape[0]>0:\n",
        "            X_list.append(Xp); y_list.append(yp)\n",
        "    if not X_list:\n",
        "        raise RuntimeError(\"No patches extracted from scenes. Check masks/thresholds.\")\n",
        "    X_all = np.concatenate(X_list, axis=0)\n",
        "    y_all = np.concatenate(y_list, axis=0)\n",
        "    print(\"Patches total:\", X_all.shape, \"Label counts:\", np.unique(y_all, return_counts=True))\n",
        "    return X_all, y_all\n",
        "\n",
        "# ============================\n",
        "# Build dataset (patches)\n",
        "# ============================\n",
        "X, y = build_dataset_from_scenes(scene_files, gdf_lake, patch_size=PATCH_SIZE, samples_per_class=SAMPLES_PER_CLASS_PER_SCENE)\n",
        "\n",
        "# If bands != expected, warn (but continue)\n",
        "bands_found = X.shape[-1]\n",
        "if bands_found != EXPECTED_BANDS:\n",
        "    print(f\"Warning: patches have {bands_found} bands (EXPECTED_BANDS={EXPECTED_BANDS}). If order differs, update code.\")\n",
        "\n",
        "# Train/val/test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=RANDOM_STATE, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp)\n",
        "print(\"Train/Val/Test sizes:\", X_train.shape[0], X_val.shape[0], X_test.shape[0])\n",
        "\n",
        "# ============================\n",
        "# PyTorch Dataset & Dataloader (3D-ready)\n",
        "# ============================\n",
        "class PatchDataset3D(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        \"\"\"\n",
        "        X: numpy array shape (N, p, p, bands)\n",
        "        We'll convert to torch tensor shape (1, bands, p, p) so that\n",
        "        Conv3D input becomes (batch, 1, D=bands, H=p, W=p)\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]  # (p, p, bands)\n",
        "        # transpose to (bands, p, p)\n",
        "        x = np.transpose(x, (2, 0, 1)).astype('float32')  # (bands, H, W)\n",
        "        # add channel dim -> (1, bands, H, W)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        # convert to torch tensor (float32)\n",
        "        return torch.from_numpy(x), torch.tensor(int(self.y[idx]), dtype=torch.long)\n",
        "\n",
        "train_ds = PatchDataset3D(X_train, y_train)\n",
        "val_ds   = PatchDataset3D(X_val, y_val)\n",
        "test_ds  = PatchDataset3D(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "# ============================\n",
        "# Compute class weights for loss\n",
        "# ============================\n",
        "cls_vals = np.unique(y_train)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=cls_vals, y=y_train)\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32).to(DEVICE)\n",
        "print(\"Class weights:\", dict(zip(cls_vals, weights)))\n",
        "\n",
        "# ============================\n",
        "# Define 3D CNN model (PyTorch)\n",
        "# ============================\n",
        "class Simple3DCNN(nn.Module):\n",
        "    def __init__(self, num_bands, num_classes):\n",
        "        \"\"\"\n",
        "        Input shape: (batch, 1, D=num_bands, H=patch, W=patch)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        in_ch = 1  # single input channel (depth = spectral)\n",
        "        self.conv1 = nn.Conv3d(in_ch, 32, kernel_size=(3,3,3), padding=(1,1,1))\n",
        "        self.bn1 = nn.BatchNorm3d(32)\n",
        "        self.conv2 = nn.Conv3d(32, 32, kernel_size=(3,3,3), padding=(1,1,1))\n",
        "        self.bn2 = nn.BatchNorm3d(32)\n",
        "        # pool spatially only (preserve spectral resolution)\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=(1,2,2))\n",
        "\n",
        "        self.conv3 = nn.Conv3d(32, 64, kernel_size=(3,3,3), padding=(1,1,1))\n",
        "        self.bn3 = nn.BatchNorm3d(64)\n",
        "        self.conv4 = nn.Conv3d(64, 64, kernel_size=(3,3,3), padding=(1,1,1))\n",
        "        self.bn4 = nn.BatchNorm3d(64)\n",
        "        self.pool2 = nn.MaxPool3d(kernel_size=(1,2,2))\n",
        "\n",
        "        self.conv5 = nn.Conv3d(64, 128, kernel_size=(3,3,3), padding=(1,1,1))\n",
        "        self.bn5 = nn.BatchNorm3d(128)\n",
        "\n",
        "        # global pooling to (B,128,1,1,1)\n",
        "        self.gap = nn.AdaptiveAvgPool3d((1,1,1))\n",
        "\n",
        "        self.fc1 = nn.Linear(128, 256)\n",
        "        self.bnfc = nn.BatchNorm1d(256)\n",
        "        self.dropfc = nn.Dropout(0.4)\n",
        "        self.out = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B,1,D,H,W)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = F.dropout3d(x, p=0.15, training=self.training)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = F.dropout3d(x, p=0.25, training=self.training)\n",
        "\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "\n",
        "        x = self.gap(x)  # (B,128,1,1,1)\n",
        "        x = x.view(x.size(0), -1)  # (B,128)\n",
        "\n",
        "        x = F.relu(self.bnfc(self.fc1(x)))\n",
        "        x = self.dropfc(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "model = Simple3DCNN(num_bands=bands_found, num_classes=NUM_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# ============================\n",
        "# Training loop (same logic)\n",
        "# ============================\n",
        "best_val_acc = 0.0\n",
        "patience = 6\n",
        "patience_counter = 0\n",
        "history = {\"train_loss\":[], \"val_loss\":[], \"train_acc\":[], \"val_acc\":[]}\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running_loss = 0.0; correct=0; total=0\n",
        "    for xb, yb in train_loader:\n",
        "        xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "        preds = out.argmax(dim=1)\n",
        "        correct += (preds==yb).sum().item()\n",
        "        total += xb.size(0)\n",
        "    train_loss = running_loss/total\n",
        "    train_acc = correct/total\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    vloss=0.0; vcorrect=0; vtotal=0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb=xb.to(DEVICE); yb=yb.to(DEVICE)\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            vloss += loss.item() * xb.size(0)\n",
        "            preds = out.argmax(dim=1)\n",
        "            vcorrect += (preds==yb).sum().item()\n",
        "            vtotal += xb.size(0)\n",
        "    val_loss = vloss/vtotal\n",
        "    val_acc = vcorrect/vtotal\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{EPOCHS}  train_loss={train_loss:.4f} train_acc={train_acc:.4f}  val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
        "\n",
        "    # early stopping & save best\n",
        "    if val_acc > best_val_acc + 1e-5:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, \"cnn3d_best.pth\"))\n",
        "        patience_counter = 0\n",
        "        print(\"  Saved best model.\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "# load best\n",
        "model.load_state_dict(torch.load(os.path.join(MODEL_SAVE_DIR, \"cnn3d_best.pth\"), map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "# ============================\n",
        "# Evaluate on test set\n",
        "# ============================\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_proba = []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        out = model(xb)\n",
        "        probs = F.softmax(out, dim=1).cpu().numpy()\n",
        "        preds = out.argmax(dim=1).cpu().numpy()\n",
        "        y_true.extend(yb.numpy().tolist())\n",
        "        y_pred.extend(preds.tolist())\n",
        "        y_proba.extend(probs.tolist())\n",
        "y_true = np.array(y_true); y_pred = np.array(y_pred); y_proba = np.vstack(y_proba)\n",
        "\n",
        "# Metrics\n",
        "acc  = accuracy_score(y_true, y_pred)\n",
        "f1_m = f1_score(y_true, y_pred, average='macro')\n",
        "f1_w = f1_score(y_true, y_pred, average='weighted')\n",
        "prec = precision_score(y_true, y_pred, average='macro')\n",
        "rec  = recall_score(y_true, y_pred, average='macro')\n",
        "kappa = cohen_kappa_score(y_true, y_pred)\n",
        "mcc = matthews_corrcoef(y_true, y_pred)\n",
        "roc_macro = roc_auc_score(label_binarize(y_true, classes=list(range(NUM_CLASSES))), y_proba, multi_class='ovr', average='macro')\n",
        "\n",
        "print(\"\\n=== 3D-CNN Test-set Performance ===\")\n",
        "print(f\"Accuracy          : {acc:.3f}\")\n",
        "print(f\"F1-score (macro)  : {f1_m:.3f}\")\n",
        "print(f\"F1-score (weighted): {f1_w:.3f}\")\n",
        "print(f\"Precision (macro) : {prec:.3f}\")\n",
        "print(f\"Recall (macro)    : {rec:.3f}\")\n",
        "print(f\"Cohen's Kappa     : {kappa:.3f}\")\n",
        "print(f\"MCC               : {mcc:.3f}\")\n",
        "print(f\"ROC–AUC (macro)   : {roc_macro:.3f}\")\n",
        "\n",
        "print(\"\\nClassification Report (per class):\")\n",
        "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
        "\n",
        "# ============================\n",
        "# Save performance to Excel\n",
        "# ============================\n",
        "summary_metrics = {\n",
        "    \"Model\": [\"3D_CNN\"],\n",
        "    \"Accuracy\": [acc],\n",
        "    \"F1_macro\": [f1_m],\n",
        "    \"F1_weighted\": [f1_w],\n",
        "    \"Precision_macro\": [prec],\n",
        "    \"Recall_macro\": [rec],\n",
        "    \"Cohen_Kappa\": [kappa],\n",
        "    \"MCC\": [mcc],\n",
        "    \"ROC_AUC_macro\": [roc_macro]\n",
        "}\n",
        "df_summary = pd.DataFrame(summary_metrics)\n",
        "df_per_class = pd.DataFrame(classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)).transpose()\n",
        "\n",
        "excel_out = os.path.join(EXCEL_SAVE_DIR, \"CNN3D_Performance_Metrics.xlsx\")\n",
        "with pd.ExcelWriter(excel_out, engine=\"openpyxl\") as writer:\n",
        "    df_summary.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    df_per_class.to_excel(writer, sheet_name=\"Per_Class\")\n",
        "print(\"Saved performance Excel to:\", excel_out)\n",
        "\n",
        "# ============================\n",
        "# Styled confusion matrix (with cell lines)\n",
        "# ============================\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(9,7))\n",
        "ax = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                 xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
        "                 annot_kws={\"size\":14, \"weight\":\"bold\"},\n",
        "                 linewidths=2, linecolor=\"black\")\n",
        "ax.set_title(\"3D-CNN — Confusion Matrix (Test)\", fontsize=20, fontweight=\"bold\")\n",
        "ax.set_xlabel(\"Predicted\", fontsize=16, fontweight=\"bold\"); ax.set_ylabel(\"Actual\", fontsize=16, fontweight=\"bold\")\n",
        "ax.tick_params(axis=\"both\", labelsize=12, width=2, length=6)\n",
        "for lbl in ax.get_xticklabels()+ax.get_yticklabels(): lbl.set_fontweight(\"bold\")\n",
        "cbar = ax.collections[0].colorbar; cbar.ax.tick_params(labelsize=12); cbar.outline.set_linewidth(2)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MAP_SAVE_DIR, \"CNN3D_Confusion_Matrix.png\"), dpi=600, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ============================\n",
        "# ROC curves plot (multiclass)\n",
        "# ============================\n",
        "n_classes = NUM_CLASSES\n",
        "y_bin = label_binarize(y_true, classes=list(range(n_classes)))\n",
        "fpr = dict(); tpr = dict(); roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_bin[:,i], y_proba[:,i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "mean_tpr /= n_classes\n",
        "fpr[\"macro\"] = all_fpr; tpr[\"macro\"] = mean_tpr; roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "plt.figure(figsize=(9,8), dpi=300)\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f\"Macro-average (AUC = {roc_auc['macro']:.3f})\", linewidth=4, color=\"black\")\n",
        "line_styles = [\"-\", \"--\", \"-.\", \":\", (0,(3,1,1,1))]\n",
        "for i,(ls,color) in enumerate(zip(line_styles, PLOT_COLORS)):\n",
        "    plt.plot(fpr[i], tpr[i], lw=2.5, linestyle=ls, color=color, label=f\"{CLASS_NAMES[i]} (AUC={roc_auc[i]:.3f})\")\n",
        "plt.plot([0,1],[0,1],'k--', lw=1.5)\n",
        "plt.xlim([0,1]); plt.ylim([0,1.05])\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=14, fontweight=\"bold\")\n",
        "plt.title(\"3D-CNN — Multiclass ROC Curves\", fontsize=18, fontweight=\"bold\")\n",
        "plt.xticks(fontsize=12); plt.yticks(fontsize=12)\n",
        "leg = plt.legend(loc=\"lower right\", fontsize=11)\n",
        "for t in leg.get_texts(): t.set_fontweight(\"bold\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MAP_SAVE_DIR, \"CNN3D_ROC_Curves.png\"), dpi=600, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ============================\n",
        "# Predict and save classification maps per scene (batch-patch prediction)\n",
        "# ============================\n",
        "def predict_map_with_cnn3d(scene_path, model, patch_size=PATCH_SIZE, batch_size=4096, save_dir=MAP_SAVE_DIR):\n",
        "    year, season, base = parse_scene_name(scene_path)\n",
        "    stack, prof = read_stack_reflectance(scene_path)\n",
        "    bands, H, W = stack.shape\n",
        "    gdf_proj = gdf_lake.to_crs(prof['crs'])\n",
        "    lake_mask = geometry_mask(gdf_proj.geometry, transform=prof['transform'], invert=True, out_shape=(H,W))\n",
        "\n",
        "    half = patch_size//2\n",
        "    pad_width = ((0,0),(half,half),(half,half))\n",
        "    stack_p = np.pad(stack, pad_width=pad_width, mode='reflect')\n",
        "    class_flat = np.full(H*W, 255, dtype=np.uint8)\n",
        "    idx_lake = np.where(lake_mask.flatten())[0]\n",
        "    print(\"Predicting for lake pixels:\", idx_lake.size)\n",
        "    n = idx_lake.size\n",
        "    for i in range(0, n, batch_size):\n",
        "        sel = idx_lake[i:i+batch_size]\n",
        "        patches = []\n",
        "        for ind in sel:\n",
        "            r = ind // W; c = ind % W\n",
        "            rp = r + half; cp = c + half\n",
        "            p = stack_p[:, rp-half:rp+half+1, cp-half:cp+half+1]  # (bands, p, p)\n",
        "            p = p.astype('float32')\n",
        "            # Add leading channel -> (1, bands, p, p)\n",
        "            p = np.expand_dims(p, axis=0)\n",
        "            patches.append(p)\n",
        "        # Xb shape: (batch, 1, bands, p, p)\n",
        "        Xb = np.stack(patches, axis=0)\n",
        "        Xb_t = torch.from_numpy(Xb).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            out = model(Xb_t)\n",
        "            probs = F.softmax(out, dim=1).cpu().numpy()\n",
        "            preds = probs.argmax(axis=1).astype(np.uint8)\n",
        "        class_flat[sel] = preds\n",
        "    class_map = class_flat.reshape(H,W)\n",
        "\n",
        "    # save GeoTIFF\n",
        "    out_tif = os.path.join(save_dir, f\"{year}_{season}_CNN3D_Map.tif\")\n",
        "    prof2 = prof.copy(); prof2.update(dtype=rasterio.uint8, count=1, nodata=255)\n",
        "    with rasterio.open(out_tif, \"w\", **prof2) as dst:\n",
        "        dst.write(class_map, 1)\n",
        "    print(\"Saved CNN3D GeoTIFF:\", out_tif)\n",
        "\n",
        "    # save PNG (clean map only)\n",
        "    plot_map = class_map.astype(float); plot_map[plot_map==255]=np.nan\n",
        "    cmap = mcolors.ListedColormap(PLOT_COLORS)\n",
        "    bounds = [-0.5,0.5,1.5,2.5,3.5,4.5]; norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
        "    fig, ax = plt.subplots(figsize=(10,10), dpi=300)\n",
        "    ax.imshow(plot_map, cmap=cmap, norm=norm, origin='upper')\n",
        "    ax.set_title(f\"{year} {season} (3D-CNN)\", fontsize=18, fontweight='bold')\n",
        "    ax.axis('off')\n",
        "    out_png = os.path.join(save_dir, f\"{year}_{season}_CNN3D_Map.png\")\n",
        "    fig.savefig(out_png, dpi=400, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"Saved CNN3D PNG:\", out_png)\n",
        "    return class_map\n",
        "\n",
        "# run prediction maps for all scenes\n",
        "for scene in scene_files:\n",
        "    predict_map_with_cnn3d(scene, model, patch_size=PATCH_SIZE, batch_size=4096, save_dir=MAP_SAVE_DIR)\n",
        "\n",
        "print(\"All done. Maps in:\", MAP_SAVE_DIR)\n",
        "print(\"Models in:\", MODEL_SAVE_DIR)\n",
        "print(\"Excel in:\", EXCEL_SAVE_DIR)\n"
      ],
      "metadata": {
        "id": "v7oNwWGaZbbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vison_Transformer"
      ],
      "metadata": {
        "id": "nIcOgqebZcvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full runnable cell: Vision Transformer (ViT) pipeline for Sentinel-2 patch classification\n",
        "# Edit paths and parameters below before running.\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from rasterio.features import geometry_mask\n",
        "import geopandas as gpd\n",
        "from skimage.morphology import dilation, disk\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                             accuracy_score, f1_score, precision_score,\n",
        "                             recall_score, roc_auc_score, roc_curve, auc,\n",
        "                             cohen_kappa_score, matthews_corrcoef)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# PyTorch imports\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "except Exception as e:\n",
        "    raise ImportError(\"PyTorch not found. Install it first, e.g. `pip install torch torchvision`\") from e\n",
        "\n",
        "# ============================\n",
        "# USER: edit these paths & params\n",
        "# ============================\n",
        "SCENES_DIR = r\"/content/drason\"     # e.g. \"/content/drive/.../Ml_ AL season\"\n",
        "SHP_PATH   = r\"/content/drive/SHP\"\n",
        "MAP_SAVE_DIR = r\"/content/drivOutput\"\n",
        "MODEL_SAVE_DIR = r\"/content/dutputt\"\n",
        "EXCEL_SAVE_DIR = r\"/content/dOutput\"\n",
        "os.makedirs(MAP_SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(EXCEL_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "PATCH_SIZE = 11                    # odd (spatial neighborhood size used to form input patches)\n",
        "# Note: patch_size_patch below controls the patch token size used by ViT patch embedding\n",
        "PATCH_SIZE_PATCH = 1               # patch token size (1 = each pixel becomes a token); larger -> fewer tokens\n",
        "SAMPLES_PER_CLASS_PER_SCENE = 400  # adjust for memory\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 40\n",
        "RANDOM_STATE = 42\n",
        "NUM_CLASSES = 5\n",
        "# Set expected bands according to your stacked TIFF order. For B2,B3,B4,B5,B6,B7,B8,B8A,B11,B12 -> 10 bands\n",
        "EXPECTED_BANDS = 10\n",
        "SCALE_REFLECTANCE = True          # True if values are 0..10000 in TIFF\n",
        "BLOOM_PERCENTILE = 85             # to set CHL_T2\n",
        "CHL_T1_FIXED = 20.0               # clean vs nutrient threshold\n",
        "VEG_SPARSE = 0.20\n",
        "VEG_DENSE  = 0.40\n",
        "NDCI_BLOOM_MIN = 0.15\n",
        "NDVI_BLOOM_MIN = 0.25\n",
        "BLOOM_DILATE_RADIUS = 2\n",
        "\n",
        "# ViT hyperparameters\n",
        "EMBED_DIM = 128\n",
        "TRANSFORMER_DEPTH = 6\n",
        "NUM_HEADS = 8\n",
        "MLP_RATIO = 4.0\n",
        "DROPOUT = 0.1\n",
        "CLS_TOKEN = True\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "random.seed(RANDOM_STATE)\n",
        "np.random.seed(RANDOM_STATE)\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "\n",
        "# color palette used for plotting & map (five classes)\n",
        "CLASS_NAMES = [\"Clean\",\"Nutrient\",\"Bloom\",\"SparsePD\",\"DensePD\"]\n",
        "PLOT_COLORS = [\"#1f78b4\",\"#33a02c\",\"#ff7f00\",\"#6a3d9a\",\"#e31a1c\"]\n",
        "\n",
        "# ============================\n",
        "# Helper: read stack reflectance\n",
        "# ============================\n",
        "def read_stack_reflectance(path):\n",
        "    \"\"\"Read stacked multi-band GeoTIFF (bands x H x W). Convert to float32 reflectance 0..1 if needed.\"\"\"\n",
        "    with rasterio.open(path) as src:\n",
        "        arr = src.read().astype(\"float32\")  # shape (bands, H, W)\n",
        "        prof = src.profile.copy()\n",
        "    finite = np.isfinite(arr)\n",
        "    if SCALE_REFLECTANCE and finite.any() and float(np.nanmax(arr[finite])) > 1.5:\n",
        "        arr = np.where(finite, arr / 10000.0, np.nan)\n",
        "    arr = np.clip(arr, 0.0, 1.5)\n",
        "    return arr, prof\n",
        "\n",
        "# ============================\n",
        "# Helper: parse scene file name\n",
        "# ============================\n",
        "def parse_scene_name(path):\n",
        "    base = os.path.basename(path).replace(\".tif\",\"\")\n",
        "    parts = base.split(\"_\",1)\n",
        "    if len(parts)==2:\n",
        "        year, season = parts\n",
        "    else:\n",
        "        year, season = \"Unknown\", base\n",
        "    return year, season, base\n",
        "\n",
        "# ============================\n",
        "# Helper: compute class map (same rules as before)\n",
        "# ============================\n",
        "def build_classes_from_stack(stack, lake_mask, CHL_T1, CHL_T2):\n",
        "    # stack: (bands, H, W); expects B2 index 0, B3 index 1, B4 index 2, B5 index 3, B8 index 6 for the standard ordering used earlier\n",
        "    B2 = stack[0]; B3 = stack[1]; B4 = stack[2]; B5 = stack[3]; B8 = stack[6]\n",
        "    eps = 1e-9\n",
        "    ndvi = (B8 - B4) / (B8 + B4 + eps)\n",
        "    ndci = (B5 - B4) / (B5 + B4 + eps)\n",
        "    chl = 14.039 + 86.115 * ndci + 194.325 * (ndci ** 2)\n",
        "    H,W = B4.shape\n",
        "    class_map = np.full((H,W), np.nan, dtype=\"float32\")\n",
        "\n",
        "    dense  = (ndvi >= VEG_DENSE) & lake_mask\n",
        "    sparse = (ndvi >= VEG_SPARSE) & (ndvi < VEG_DENSE) & lake_mask\n",
        "    water  = (ndvi < VEG_SPARSE) & lake_mask\n",
        "\n",
        "    class_map[dense]  = 4\n",
        "    class_map[sparse] = 3\n",
        "\n",
        "    bloom_core = (chl >= CHL_T2) & water\n",
        "    bloom_spectral = ((ndci > NDCI_BLOOM_MIN) & (ndvi > NDVI_BLOOM_MIN)) & water\n",
        "    bloom = bloom_core | bloom_spectral\n",
        "    if BLOOM_DILATE_RADIUS > 0:\n",
        "        bloom = dilation(bloom, disk(BLOOM_DILATE_RADIUS)) & water\n",
        "    class_map[bloom] = 2\n",
        "\n",
        "    water_remain = water & (~bloom)\n",
        "    class_map[(chl < CHL_T1) & water_remain] = 0\n",
        "    class_map[(chl >= CHL_T1) & water_remain] = 1\n",
        "\n",
        "    return class_map, chl, ndvi, ndci\n",
        "\n",
        "# ============================\n",
        "# PASS 1: scan scenes to collect CHL percentiles -> CHL_T2\n",
        "# ============================\n",
        "scene_files = sorted(glob.glob(os.path.join(SCENES_DIR, \"*.tif\")))\n",
        "if len(scene_files)==0:\n",
        "    raise RuntimeError(\"No .tif scenes found in SCENES_DIR. Edit SCENES_DIR path.\")\n",
        "\n",
        "gdf_lake = gpd.read_file(SHP_PATH)\n",
        "print(\"Found scenes:\", len(scene_files), \"Shapefile rows:\", len(gdf_lake))\n",
        "\n",
        "all_chl = []\n",
        "for scene_path in scene_files:\n",
        "    print(\"Collecting chl from:\", os.path.basename(scene_path))\n",
        "    stack, prof = read_stack_reflectance(scene_path)\n",
        "    H = stack.shape[1]; W = stack.shape[2]\n",
        "    gdf_proj = gdf_lake.to_crs(prof['crs'])\n",
        "    lake_mask = geometry_mask(gdf_proj.geometry, transform=prof['transform'], invert=True, out_shape=(H,W))\n",
        "    _, chl, _, _ = build_classes_from_stack(stack, lake_mask, CHL_T1_FIXED, CHL_T1_FIXED+10)  # CHL_T2 placeholder\n",
        "    valid = lake_mask & np.isfinite(chl)\n",
        "    if np.any(valid):\n",
        "        all_chl.append(chl[valid])\n",
        "if len(all_chl)==0:\n",
        "    raise RuntimeError(\"No valid chl values inside lake for any scene.\")\n",
        "all_chl = np.concatenate(all_chl)\n",
        "p50,p75,p85,p90,p95 = np.percentile(all_chl, [50,75,85,90,95])\n",
        "CHL_T1 = CHL_T1_FIXED\n",
        "CHL_T2 = float(np.percentile(all_chl, BLOOM_PERCENTILE))\n",
        "print(f\"Chl percentiles: 50%={p50:.2f},75%={p75:.2f},85%={p85:.2f},90%={p90:.2f},95%={p95:.2f}\")\n",
        "print(f\"Using CHL_T1={CHL_T1:.2f}, CHL_T2({BLOOM_PERCENTILE}th)={CHL_T2:.2f}\")\n",
        "\n",
        "# ============================\n",
        "# Patch extraction functions (identical to earlier)\n",
        "# ============================\n",
        "def extract_patches_from_scene(stack, class_map, lake_mask, patch_size=11, samples_per_class=400):\n",
        "    half = patch_size//2\n",
        "    bands, H, W = stack.shape\n",
        "    pad_width = ((0,0),(half,half),(half,half))\n",
        "    stack_p = np.pad(stack, pad_width=pad_width, mode='reflect')\n",
        "    X = []\n",
        "    y = []\n",
        "    flat_cls = class_map.flatten()\n",
        "    flat_lake = lake_mask.flatten()\n",
        "    for cls in range(NUM_CLASSES):\n",
        "        idxs = np.where((flat_cls==cls) & (flat_lake))[0]\n",
        "        if idxs.size==0:\n",
        "            continue\n",
        "        sel = idxs if idxs.size <= samples_per_class else np.random.choice(idxs, samples_per_class, replace=False)\n",
        "        for ind in sel:\n",
        "            r = ind // W; c = ind % W\n",
        "            rp = r + half; cp = c + half\n",
        "            patch = stack_p[:, rp-half:rp+half+1, cp-half:cp+half+1]  # (bands, p, p)\n",
        "            patch = np.transpose(patch, (1,2,0))  # (p, p, bands)\n",
        "            X.append(patch)\n",
        "            y.append(cls)\n",
        "    if len(X)==0:\n",
        "        return np.empty((0,patch_size,patch_size,bands)), np.empty((0,), dtype=int)\n",
        "    X = np.stack(X, axis=0).astype('float32')\n",
        "    y = np.array(y, dtype=int)\n",
        "    return X,y\n",
        "\n",
        "def build_dataset_from_scenes(scene_files, gdf_lake, patch_size=11, samples_per_class=400):\n",
        "    X_list=[]; y_list=[]\n",
        "    for scene_path in scene_files:\n",
        "        print(\"Scene:\", os.path.basename(scene_path))\n",
        "        stack, prof = read_stack_reflectance(scene_path)\n",
        "        H = stack.shape[1]; W = stack.shape[2]\n",
        "        gdf_proj = gdf_lake.to_crs(prof['crs'])\n",
        "        lake_mask = geometry_mask(gdf_proj.geometry, transform=prof['transform'], invert=True, out_shape=(H,W))\n",
        "        class_map, chl, ndvi, ndci = build_classes_from_stack(stack, lake_mask, CHL_T1, CHL_T2)\n",
        "        Xp, yp = extract_patches_from_scene(stack, class_map, lake_mask, patch_size=patch_size, samples_per_class=samples_per_class)\n",
        "        if Xp.shape[0]>0:\n",
        "            X_list.append(Xp); y_list.append(yp)\n",
        "    if not X_list:\n",
        "        raise RuntimeError(\"No patches extracted from scenes. Check masks/thresholds.\")\n",
        "    X_all = np.concatenate(X_list, axis=0)\n",
        "    y_all = np.concatenate(y_list, axis=0)\n",
        "    print(\"Patches total:\", X_all.shape, \"Label counts:\", np.unique(y_all, return_counts=True))\n",
        "    return X_all, y_all\n",
        "\n",
        "# ============================\n",
        "# Build dataset (patches)\n",
        "# ============================\n",
        "X, y = build_dataset_from_scenes(scene_files, gdf_lake, patch_size=PATCH_SIZE, samples_per_class=SAMPLES_PER_CLASS_PER_SCENE)\n",
        "\n",
        "bands_found = X.shape[-1]\n",
        "if bands_found != EXPECTED_BANDS:\n",
        "    print(f\"Warning: patches have {bands_found} bands (EXPECTED_BANDS={EXPECTED_BANDS}). If order differs, update code.\")\n",
        "\n",
        "# Train/val/test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=RANDOM_STATE, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp)\n",
        "print(\"Train/Val/Test sizes:\", X_train.shape[0], X_val.shape[0], X_test.shape[0])\n",
        "\n",
        "# ============================\n",
        "# PyTorch Dataset & Dataloader for ViT\n",
        "# ============================\n",
        "class PatchDatasetViT(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"\n",
        "        X: numpy (N, p, p, bands)  (spatial-first)\n",
        "        Return: (C,H,W) float32 where C = bands (channel-first)\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        patch = self.X[idx]  # (p, p, bands)\n",
        "        # convert to (bands, p, p)\n",
        "        patch = np.transpose(patch, (2,0,1)).astype('float32')\n",
        "        return torch.from_numpy(patch), torch.tensor(int(self.y[idx]), dtype=torch.long)\n",
        "\n",
        "train_ds = PatchDatasetViT(X_train, y_train)\n",
        "val_ds   = PatchDatasetViT(X_val, y_val)\n",
        "test_ds  = PatchDatasetViT(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "# ============================\n",
        "# Compute class weights for loss\n",
        "# ============================\n",
        "cls_vals = np.unique(y_train)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=cls_vals, y=y_train)\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32).to(DEVICE)\n",
        "print(\"Class weights:\", dict(zip(cls_vals, weights)))\n",
        "\n",
        "# ============================\n",
        "# ViT model definition (simple, configurable)\n",
        "# ============================\n",
        "class PatchEmbed(nn.Module):\n",
        "    \"\"\"Convert (B, C, H, W) -> (B, num_patches, embed_dim) using Conv2d.\"\"\"\n",
        "    def __init__(self, in_chans, embed_dim, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        # conv to produce patch embeddings; out_channels = embed_dim\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, H, W)\n",
        "        x = self.proj(x)           # (B, embed_dim, H/ps, W/ps)\n",
        "        B, E, Hf, Wf = x.shape\n",
        "        x = x.flatten(2).transpose(1,2)  # (B, num_patches, embed_dim)\n",
        "        return x, (Hf, Wf)\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self, in_chans, num_classes, embed_dim=128, depth=6, num_heads=8, mlp_ratio=4.0, patch_size=1, dropout=0.1, use_cls_token=True):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.patch_embed = PatchEmbed(in_chans, embed_dim, patch_size)\n",
        "        self.use_cls_token = use_cls_token\n",
        "\n",
        "        # placeholder for num_patches until forward (pos_embed shape depends on grid)\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1,1,embed_dim)) if use_cls_token else None\n",
        "        self.pos_embed = None\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=int(embed_dim*mlp_ratio), dropout=dropout, activation='gelu')\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "        # init\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02) if self.cls_token is not None else None\n",
        "        # pos_embed will be created on first forward when we know num_patches\n",
        "\n",
        "    def _init_pos_embed(self, num_patches, device):\n",
        "        # create pos_embed shape (1, n_tokens, embed_dim) ; n_tokens = num_patches + (1 if cls)\n",
        "        n_tokens = num_patches + (1 if self.use_cls_token else 0)\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, n_tokens, self.embed_dim).to(device))\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, H, W)\n",
        "        B = x.shape[0]\n",
        "        x, (Hf, Wf) = self.patch_embed(x)  # x: (B, num_patches, embed_dim)\n",
        "        num_patches = x.shape[1]\n",
        "        device = x.device\n",
        "        if self.pos_embed is None or self.pos_embed.shape[1] != num_patches + (1 if self.use_cls_token else 0):\n",
        "            self._init_pos_embed(num_patches, device)\n",
        "\n",
        "        if self.use_cls_token:\n",
        "            cls_tok = self.cls_token.expand(B, -1, -1)  # (B,1,embed_dim)\n",
        "            x = torch.cat([cls_tok, x], dim=1)          # (B, 1+num_patches, embed_dim)\n",
        "        x = x + self.pos_embed\n",
        "        # transformer expects (seq_len, batch, embed_dim) by default, so transpose\n",
        "        x = x.transpose(0,1)  # (seq_len, B, E)\n",
        "        x = self.transformer(x)  # (seq_len, B, E)\n",
        "        x = x.transpose(0,1)  # (B, seq_len, E)\n",
        "        x = self.norm(x)\n",
        "        # classification token or mean pooling\n",
        "        if self.use_cls_token:\n",
        "            rep = x[:,0]  # (B, E)\n",
        "        else:\n",
        "            rep = x.mean(dim=1)\n",
        "        logits = self.head(rep)\n",
        "        return logits\n",
        "\n",
        "# instantiate model\n",
        "model = ViT(in_chans=bands_found, num_classes=NUM_CLASSES, embed_dim=EMBED_DIM, depth=TRANSFORMER_DEPTH,\n",
        "            num_heads=NUM_HEADS, mlp_ratio=MLP_RATIO, patch_size=PATCH_SIZE_PATCH, dropout=DROPOUT, use_cls_token=CLS_TOKEN).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# ============================\n",
        "# Training loop\n",
        "# ============================\n",
        "best_val_acc = 0.0\n",
        "patience = 8\n",
        "patience_counter = 0\n",
        "history = {\"train_loss\":[], \"val_loss\":[], \"train_acc\":[], \"val_acc\":[]}\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running_loss = 0.0; correct=0; total=0\n",
        "    for xb, yb in train_loader:\n",
        "        xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "        preds = out.argmax(dim=1)\n",
        "        correct += (preds==yb).sum().item()\n",
        "        total += xb.size(0)\n",
        "    train_loss = running_loss/total\n",
        "    train_acc = correct/total\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    vloss=0.0; vcorrect=0; vtotal=0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb=xb.to(DEVICE); yb=yb.to(DEVICE)\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            vloss += loss.item() * xb.size(0)\n",
        "            preds = out.argmax(dim=1)\n",
        "            vcorrect += (preds==yb).sum().item()\n",
        "            vtotal += xb.size(0)\n",
        "    val_loss = vloss/vtotal\n",
        "    val_acc = vcorrect/vtotal\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{EPOCHS}  train_loss={train_loss:.4f} train_acc={train_acc:.4f}  val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
        "\n",
        "    # early stopping & save best\n",
        "    if val_acc > best_val_acc + 1e-5:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, \"vit_best.pth\"))\n",
        "        patience_counter = 0\n",
        "        print(\"  Saved best model.\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "# load best\n",
        "model.load_state_dict(torch.load(os.path.join(MODEL_SAVE_DIR, \"vit_best.pth\"), map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "# ============================\n",
        "# Evaluate on test set\n",
        "# ============================\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_proba = []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        out = model(xb)\n",
        "        probs = F.softmax(out, dim=1).cpu().numpy()\n",
        "        preds = out.argmax(dim=1).cpu().numpy()\n",
        "        y_true.extend(yb.numpy().tolist())\n",
        "        y_pred.extend(preds.tolist())\n",
        "        y_proba.extend(probs.tolist())\n",
        "y_true = np.array(y_true); y_pred = np.array(y_pred); y_proba = np.vstack(y_proba)\n",
        "\n",
        "# Metrics\n",
        "acc  = accuracy_score(y_true, y_pred)\n",
        "f1_m = f1_score(y_true, y_pred, average='macro')\n",
        "f1_w = f1_score(y_true, y_pred, average='weighted')\n",
        "prec = precision_score(y_true, y_pred, average='macro')\n",
        "rec  = recall_score(y_true, y_pred, average='macro')\n",
        "kappa = cohen_kappa_score(y_true, y_pred)\n",
        "mcc = matthews_corrcoef(y_true, y_pred)\n",
        "roc_macro = roc_auc_score(label_binarize(y_true, classes=list(range(NUM_CLASSES))), y_proba, multi_class='ovr', average='macro')\n",
        "\n",
        "print(\"\\n=== ViT Test-set Performance ===\")\n",
        "print(f\"Accuracy          : {acc:.3f}\")\n",
        "print(f\"F1-score (macro)  : {f1_m:.3f}\")\n",
        "print(f\"F1-score (weighted): {f1_w:.3f}\")\n",
        "print(f\"Precision (macro) : {prec:.3f}\")\n",
        "print(f\"Recall (macro)    : {rec:.3f}\")\n",
        "print(f\"Cohen's Kappa     : {kappa:.3f}\")\n",
        "print(f\"MCC               : {mcc:.3f}\")\n",
        "print(f\"ROC–AUC (macro)   : {roc_macro:.3f}\")\n",
        "\n",
        "print(\"\\nClassification Report (per class):\")\n",
        "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
        "\n",
        "# ============================\n",
        "# Save performance to Excel\n",
        "# ============================\n",
        "summary_metrics = {\n",
        "    \"Model\": [\"ViT\"],\n",
        "    \"Accuracy\": [acc],\n",
        "    \"F1_macro\": [f1_m],\n",
        "    \"F1_weighted\": [f1_w],\n",
        "    \"Precision_macro\": [prec],\n",
        "    \"Recall_macro\": [rec],\n",
        "    \"Cohen_Kappa\": [kappa],\n",
        "    \"MCC\": [mcc],\n",
        "    \"ROC_AUC_macro\": [roc_macro]\n",
        "}\n",
        "df_summary = pd.DataFrame(summary_metrics)\n",
        "df_per_class = pd.DataFrame(classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)).transpose()\n",
        "\n",
        "excel_out = os.path.join(EXCEL_SAVE_DIR, \"ViT_Performance_Metrics.xlsx\")\n",
        "with pd.ExcelWriter(excel_out, engine=\"openpyxl\") as writer:\n",
        "    df_summary.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    df_per_class.to_excel(writer, sheet_name=\"Per_Class\")\n",
        "print(\"Saved performance Excel to:\", excel_out)\n",
        "\n",
        "# ============================\n",
        "# Styled confusion matrix (with cell lines)\n",
        "# ============================\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(9,7))\n",
        "ax = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                 xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
        "                 annot_kws={\"size\":14, \"weight\":\"bold\"},\n",
        "                 linewidths=2, linecolor=\"black\")\n",
        "ax.set_title(\"ViT — Confusion Matrix (Test)\", fontsize=20, fontweight=\"bold\")\n",
        "ax.set_xlabel(\"Predicted\", fontsize=16, fontweight=\"bold\"); ax.set_ylabel(\"Actual\", fontsize=16, fontweight=\"bold\")\n",
        "ax.tick_params(axis=\"both\", labelsize=12, width=2, length=6)\n",
        "for lbl in ax.get_xticklabels()+ax.get_yticklabels(): lbl.set_fontweight(\"bold\")\n",
        "cbar = ax.collections[0].colorbar; cbar.ax.tick_params(labelsize=12); cbar.outline.set_linewidth(2)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MAP_SAVE_DIR, \"ViT_Confusion_Matrix.png\"), dpi=600, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ============================\n",
        "# ROC curves plot (multiclass)\n",
        "# ============================\n",
        "n_classes = NUM_CLASSES\n",
        "y_bin = label_binarize(y_true, classes=list(range(n_classes)))\n",
        "fpr = dict(); tpr = dict(); roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_bin[:,i], y_proba[:,i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "mean_tpr /= n_classes\n",
        "fpr[\"macro\"] = all_fpr; tpr[\"macro\"] = mean_tpr; roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "plt.figure(figsize=(9,8), dpi=300)\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f\"Macro-average (AUC = {roc_auc['macro']:.3f})\", linewidth=4, color=\"black\")\n",
        "line_styles = [\"-\", \"--\", \"-.\", \":\", (0,(3,1,1,1))]\n",
        "for i,(ls,color) in enumerate(zip(line_styles, PLOT_COLORS)):\n",
        "    plt.plot(fpr[i], tpr[i], lw=2.5, linestyle=ls, color=color, label=f\"{CLASS_NAMES[i]} (AUC={roc_auc[i]:.3f})\")\n",
        "plt.plot([0,1],[0,1],'k--', lw=1.5)\n",
        "plt.xlim([0,1]); plt.ylim([0,1.05])\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=14, fontweight=\"bold\")\n",
        "plt.title(\"ViT — Multiclass ROC Curves\", fontsize=18, fontweight=\"bold\")\n",
        "plt.xticks(fontsize=12); plt.yticks(fontsize=12)\n",
        "leg = plt.legend(loc=\"lower right\", fontsize=11)\n",
        "for t in leg.get_texts(): t.set_fontweight(\"bold\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MAP_SAVE_DIR, \"ViT_ROC_Curves.png\"), dpi=600, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "mxdrwqaPZgPx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}